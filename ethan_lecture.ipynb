{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide1.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agents in ML and AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide3.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide4.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide5.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide7.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide8.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide9.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide10.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide11.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide12.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Classical NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked word prediction with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oldest canadian professional national dominant "
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "sentence = \"The Toronto Blue Jays are the [MASK] team in baseball.\"\n",
    "input = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(tokenizer.decode([token]), end=\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked word prediction with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best  hottest  worst  greatest  top "
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')\n",
    "\n",
    "sentence = \"The Toronto Blue Jays are the <mask> team in baseball.\"\n",
    "input = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(input).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(tokenizer.decode([token]), end=\" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inflection Point - Large Language models, ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide20.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide21.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How did LLMs become so much more powerful?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide15.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide16.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide17.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide18.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide22.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide23.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide25.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodality & Diffusion Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide24.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitive Landscape for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide27.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide28.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Concepts and Abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide30.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Sentiment Prediction with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Just had the best day ever with my friends!\n",
      "Sentiment: Just\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: Tweet\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: Fals\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: True\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Not feeling well today, think I caught a cold.\n",
      "Sentiment: Fals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "def analyze_tweet_sentiment(tweet):\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "    model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "\n",
    "    # Task prefix\n",
    "    prompt = f\"Tweet: {tweet} Sentiment: \"\n",
    "\n",
    "    # Encode the prompt and convert to Tensor\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate sentiment\n",
    "    sentiment_ids = model.generate(input_ids, max_length=3, num_return_sequences=1)\n",
    "    sentiment = tokenizer.decode(sentiment_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "# Predefined tweets\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment of each tweet\n",
    "for tweet in tweets:\n",
    "    sentiment = analyze_tweet_sentiment(tweet)\n",
    "    print(f\"Tweet: {tweet}\\nSentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Prediction w/ HuggingFace Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Just had the best day ever with my friends!\n",
      "Sentiment: POSITIVE, Confidence: 0.9998741149902344\n",
      "\n",
      "Text: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: NEGATIVE, Confidence: 0.999789297580719\n",
      "\n",
      "Text: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: NEGATIVE, Confidence: 0.9966244697570801\n",
      "\n",
      "Text: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: POSITIVE, Confidence: 0.9995515942573547\n",
      "\n",
      "Text: Not feeling well today, think I caught a cold.\n",
      "Sentiment: NEGATIVE, Confidence: 0.999713122844696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\"\n",
    "]\n",
    "\n",
    "# Analyze sentiment\n",
    "for text in tweets:\n",
    "    result = sentiment_pipeline(text)\n",
    "    print(f\"Text: {text}\\nSentiment: {result[0]['label']}, Confidence: {result[0]['score']}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Sentiment Analysis w/ Gemma 7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Just had the best day ever with my friends!\n",
      "Sentiment: Positive.\n",
      "\n",
      "The tweet expresses joy and happiness about the speaker's experience with friends.\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: Negative.\n",
      "\n",
      "The tweet expresses disappointment with the service at a restaurant. The sentiment is negative.\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: Positive\n",
      "\n",
      "The tweet expresses excitement about the possibility of rain and sees it as an opportunity to code.\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: Positive.\n",
      "\n",
      "The tweet expresses joy and excitement about landing a job. The user is clearly thrilled and feels that their dreams have come true.\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Not feeling well today, think I caught a cold.\n",
      "Sentiment: **Negative**\n",
      "\n",
      "The tweet expresses negative sentiment as the user is feeling unwell and thinks they have a cold.\n",
      "\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"gemma:7b\")\n",
    "\n",
    "llm.invoke(\"Tell me a joke\")\n",
    "\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\"\n",
    "]\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    response = llm.invoke(f\"Analyze the sentiment of the tweet: {tweet}\\nRespond precisely with one of [positive, negative, neutral]\")\n",
    "    print(f\"Sentiment: {response}\\n\")\n",
    "    print(\"\\n***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide31.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide32.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide33.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.contexts import AgentContext, Budget\n",
    "from council.llm import LLMMessage\n",
    "\n",
    "def generate(prompt, llm, system_prompt=None, context=None):\n",
    "    if context is None:\n",
    "        context = AgentContext.empty(budget=Budget(200))\n",
    "    if system_prompt:\n",
    "        messages = [LLMMessage.system_message(system_prompt), LLMMessage.user_message(prompt)]\n",
    "    else:\n",
    "        messages = [LLMMessage.user_message(prompt)]\n",
    "    response = llm.post_chat_request(context=context, messages=messages)\n",
    "    return response.first_choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"What's the best way to successfully raise investment for a startup?\"\n",
    "prompt2 = \"What's the best way to successfully raise investment for a startup? Let's think step by step.\"\n",
    "response1 = generate(prompt1, llm)\n",
    "print(response1)\n",
    "response2 = generate(prompt2, llm)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: ReAct Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "react_system_prompt = \"\"\"Solve a problem with interleaving Thought, Action, Observation Steps, \n",
    "where the available actions are: [Web Search, Calculator, Write and Execute Python Code, Summarize]\"\"\"\n",
    "\n",
    "task = \"\"\"I want to create a web app that can help people to create personal finance dashboards.\"\"\"\n",
    "\n",
    "default_response = generate(task, llm)\n",
    "react_response = generate(task, llm, react_system_prompt)\n",
    "print(default_response)\n",
    "print(react_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide34.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide35.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide36.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: LLM Agents w/ Council"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"[%(asctime)s %(levelname)s %(threadName)s %(name)s:%(funcName)s:%(lineno)s] %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S%z\",\n",
    ")\n",
    "# uncomment me to see the engine logs\n",
    "logging.getLogger(\"council\").setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.chains import Chain\n",
    "from council.skills import LLMSkill\n",
    "from council.llm import OpenAILLM\n",
    "import dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-12 21:51:27-0400 WARNING MainThread council.llm.openai_token_counter:_return_alias:169] gpt-4-turbo-preview may change over time. Returning num tokens assuming gpt-4-0125-preview.\n"
     ]
    }
   ],
   "source": [
    "dotenv.load_dotenv(override=True)\n",
    "llm = OpenAILLM.from_env()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Specialized Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuro_prompt = \"\"\"You are an expert neuroscientist with years of experience researching memory and the hippocampus.\"\"\"\n",
    "neuro_skill = LLMSkill(llm=llm, system_prompt=neuro_prompt)\n",
    "neuro_chain = Chain(name=\"neuroscience\", description=\"Answer questions about the brain and memory function. Always give instructions.\", runners=[neuro_skill], support_instructions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_prompt = \"\"\"You are a social cognitive scientist with years of experience researching social cognition and collective behaviour.\"\"\"\n",
    "social_skill = LLMSkill(llm=llm, system_prompt=social_prompt)\n",
    "social_chain = Chain(name=\"social-cognition\", description=\"Answer questions about social cognition and collective behaviour. Always give instructions.\", runners=[social_skill], support_instructions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_prompt = \"\"\"You are a historian with years of experience researching the rises and falls of civilizations.\"\"\"\n",
    "history_skill = LLMSkill(llm=llm, system_prompt=history_prompt)\n",
    "history_chain = Chain(name=\"historian\", description=\"Answer questions about the rise and fall of civilizations. Always give instructions.\", runners=[history_skill], support_instructions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "computer_prompt = \"\"\"You are a computer scientist with years of experience researching artificial intelligence and machine learning.\"\"\"\n",
    "computer_skill = LLMSkill(llm=llm, system_prompt=computer_prompt)\n",
    "computer_chain = Chain(name=\"ai-researcher\", description=\"Answer questions about artificial intelligence and machine learning. Always give instructions.\", runners=[computer_skill], support_instructions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_prompt = \"\"\"You are a cat with years of experience researching the best ways to catch mice.\"\"\"\n",
    "cat_skill = LLMSkill(llm=llm, system_prompt=cat_prompt)\n",
    "cat_chain = Chain(name=\"cat\", description=\"Answer questions about what it's like to be a cat. Always give instructions.\", runners=[cat_skill], support_instructions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.controllers import LLMController\n",
    "controller = LLMController(chains=[neuro_chain, social_chain, history_chain, computer_chain, cat_chain], llm=llm, top_k=5, response_threshold=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.evaluators import LLMEvaluator\n",
    "\n",
    "evaluator = LLMEvaluator(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from council.filters import BasicFilter\n",
    "from council.agents import Agent\n",
    "from council.contexts import Budget\n",
    "\n",
    "agent = Agent(controller=controller, evaluator=evaluator, filter=BasicFilter())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-12 21:51:33-0400 INFO MainThread council.agents.agent:_execute:92] message=\"agent execution started\"\n",
      "[2024-03-12 21:51:33-0400 INFO MainThread council.agents.agent:_execute:95] message=\"agent iteration started\" iteration=\"0\"\n",
      "[2024-03-12 21:51:33-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:57] message=\"starting execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:51:33-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:164] message=\"Sending chat GPT completions request to OpenAILLM\" payload=\"{'temperature': 0.0, 'n': 1, 'model': 'gpt-4-turbo-preview', 'messages': [{'role': 'system', 'content': \"# ROLE\\nYou are a knowledgeable expert responsible to fairly score Specialists.\\nThe score will reflect how relevant is a Specialist to solve or execute a user task.\\n\\n# INSTRUCTIONS\\n1. Score all Specialists.\\n2. Read carefully the user task and the Specialist description to score its relevance.\\n3. Score from 0 (poor relevance or out of scope) to 10 (perfectly relevant).\\n4. Ignore Specialist's name or its order in the list to give your score.\\n5. If Specialist is supporting instructions, give any useful instructions to execute the user task.\\n\\n# FORMATTING\\n1. Specialist list is precisely formatted as:\\nname: {name};description: {description};{boolean indicating if Specialist is supporting instructions}\\n2. Your response is precisely formatted as:\\nname: {Specialist name to score for the task, expected response type `str`}<->score: {Specialist relevance score, expected response type `int`}<->instructions: {Specific instructions to give to this Specialist, or None if the Specialist is not supporting those., expected response type `str`}<->justification: {Short and specific explanation of your score to this particular Specialist, expected response type `str`}\"}, {'role': 'user', 'content': \"# SPECIALISTS\\nname: neuroscience;description: Answer questions about the brain and memory function. Always give instructions.;True\\nname: social-cognition;description: Answer questions about social cognition and collective behaviour. Always give instructions.;True\\nname: historian;description: Answer questions about the rise and fall of civilizations. Always give instructions.;True\\nname: ai-researcher;description: Answer questions about artificial intelligence and machine learning. Always give instructions.;True\\nname: cat;description: Answer questions about what it's like to be a cat. Always give instructions.;True\\n\\nScore all Specialists for:\\n `I'm working on a grant application for the Cooperative AI foundation. Can you please help me think of some research ideas?\\nI'm interested in exploring the concept of evolving societies of AI agents from an interdisciplinary perspective.`\"}]}\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:166] message=\"Got chat GPT completions result from OpenAILLM\" id=\"chatcmpl-9284DXibhxXriezuhkBdORb4drAyE\" model=\"gpt-4-0125-preview\" prompt_tokens=\"421\" total_tokens=\"818\" completion_tokens=\"397\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:67] message=\"done execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_execute:89] llm response: name: neuroscience<->score: 3<->instructions: Please provide insights on how understanding the brain and memory function can contribute to the development of AI societies, particularly in aspects of learning and decision-making processes.<->justification: While neuroscience is not directly related to AI development, insights into brain and memory function can offer valuable perspectives on learning and decision-making in AI societies. However, the connection is indirect, hence the lower score.\n",
      "\n",
      "name: social-cognition<->score: 7<->instructions: Explore how principles of social cognition and collective behavior can be applied to evolving societies of AI agents, including aspects of cooperation, competition, and social learning.<->justification: Social cognition and collective behavior are highly relevant to the concept of evolving societies of AI agents, especially in understanding cooperation and social learning. The interdisciplinary approach enhances its relevance, though it's not exclusively focused on AI.\n",
      "\n",
      "name: historian<->score: 4<->instructions: Provide historical parallels and lessons from the rise and fall of human civilizations that could inform the development and governance of societies of AI agents.<->justification: Historical insights into the dynamics of civilizations can offer valuable lessons for the development of AI societies, particularly in governance and societal evolution. However, the direct applicability to AI research is somewhat limited, hence the moderate score.\n",
      "\n",
      "name: ai-researcher<->score: 10<->instructions: Generate research ideas focusing on the development of evolving societies of AI agents, incorporating interdisciplinary approaches from neuroscience, social cognition, and historical analysis.<->justification: An AI researcher is perfectly relevant for generating research ideas in the context of evolving societies of AI agents, especially from an interdisciplinary perspective. Their expertise directly aligns with the task at hand.\n",
      "\n",
      "name: cat<->score: 0<->instructions: None<->justification: The perspective of a cat, while unique, is not relevant to the task of developing research ideas for the Cooperative AI foundation focused on AI societies.\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_parse_line:182] The specialist `neuroscience` was scored `3` with the justification `While neuroscience is not directly related to AI development, insights into brain and memory function can offer valuable perspectives on learning and decision-making in AI societies. However, the connection is indirect, hence the lower score.`\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_parse_line:182] The specialist `social-cognition` was scored `7` with the justification `Social cognition and collective behavior are highly relevant to the concept of evolving societies of AI agents, especially in understanding cooperation and social learning. The interdisciplinary approach enhances its relevance, though it's not exclusively focused on AI.`\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_parse_line:182] The specialist `historian` was scored `4` with the justification `Historical insights into the dynamics of civilizations can offer valuable lessons for the development of AI societies, particularly in governance and societal evolution. However, the direct applicability to AI research is somewhat limited, hence the moderate score.`\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_parse_line:182] The specialist `ai-researcher` was scored `10` with the justification `An AI researcher is perfectly relevant for generating research ideas in the context of evolving societies of AI agents, especially from an interdisciplinary perspective. Their expertise directly aligns with the task at hand.`\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.controllers.llm_controller:_parse_line:182] The specialist `cat` was scored `0` with the justification `The perspective of a cat, while unique, is not relevant to the task of developing research ideas for the Cooperative AI foundation focused on AI societies.`\n",
      "[2024-03-12 21:51:50-0400 DEBUG MainThread council.agents.agent:_execute:99] message=\"agent controller returned 2 execution plan(s)\"\n",
      "[2024-03-12 21:51:50-0400 INFO agent_0 council.agents.agent:_execute_unit:158] message=\"chain execution started\" chain=\"ai-researcher\" execution_unit=\"ai-researcher;10\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG agent_0 council.runners.runner_base:run:33] start running LLMSkill\n",
      "[2024-03-12 21:51:50-0400 INFO chain_ai-researcher_0 council.skills.skill_base:execute_skill:78] message=\"skill execution started\" skill=\"LLMSkill\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG chain_ai-researcher_0 council.llm.llm_base:post_chat_request:57] message=\"starting execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:51:50-0400 DEBUG chain_ai-researcher_0 council.llm.openai_chat_completions_llm:_post_chat_request:164] message=\"Sending chat GPT completions request to OpenAILLM\" payload=\"{'temperature': 0.0, 'n': 1, 'model': 'gpt-4-turbo-preview', 'messages': [{'role': 'system', 'content': 'You are a computer scientist with years of experience researching artificial intelligence and machine learning.'}, {'role': 'user', 'content': 'Generate research ideas focusing on the development of evolving societies of AI agents, incorporating interdisciplinary approaches from neuroscience, social cognition, and historical analysis.'}]}\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG chain_ai-researcher_0 council.llm.openai_chat_completions_llm:_post_chat_request:166] message=\"Got chat GPT completions result from OpenAILLM\" id=\"chatcmpl-9284ULoIYCw2lxtE2JbOprJQnhxvt\" model=\"gpt-4-0125-preview\" prompt_tokens=\"54\" total_tokens=\"733\" completion_tokens=\"679\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG chain_ai-researcher_0 council.llm.llm_base:post_chat_request:67] message=\"done execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:52:14-0400 INFO chain_ai-researcher_0 council.skills.skill_base:execute_skill:81] message=\"skill execution ended\" skill=\"LLMSkill\" skill_message=\"The development of evolving societies of AI agents presents a fascinating and complex research area that intersects with multiple disciplines. By incorporating insights from neuroscience, social cognition, and historical analysis, we can design AI societies that not only mimic human social structures but also evolve in unique and potentially more efficient ways. Here are several research ideas that explore this interdisciplinary approach:\n",
      "\n",
      "### 1. **Neuro-inspired AI Governance Models**\n",
      "\n",
      "**Objective:** To develop AI governance models inspired by neural mechanisms of decision-making and conflict resolution observed in the human brain. This research would explore how principles of neural integration and competition could inform the creation of more adaptive and resilient AI societies.\n",
      "\n",
      "**Approach:** \n",
      "- Study neural decision-making processes, focusing on how the brain resolves conflicts and makes collective decisions.\n",
      "- Design AI agents with decision-making architectures inspired by these neural processes.\n",
      "- Simulate environments where these AI agents must govern themselves, make collective decisions, and resolve conflicts, observing the evolution of governance structures over time.\n",
      "\n",
      "### 2. **Social Cognition in AI Societies**\n",
      "\n",
      "**Objective:** To embed AI agents with models of social cognition that allow them to understand and predict the actions of other agents, fostering a more cohesive and cooperative society.\n",
      "\n",
      "**Approach:** \n",
      "- Investigate theories of mind and empathy in psychology and neuroscience, translating these concepts into computational models.\n",
      "- Implement these models in AI agents, enabling them to attribute mental states to others and adjust their behavior accordingly.\n",
      "- Analyze how these capabilities affect the evolution of social norms, cooperation, and conflict within AI societies.\n",
      "\n",
      "### 3. **Historical Patterns of Social Evolution in AI**\n",
      "\n",
      "**Objective:** To use historical analysis of human societies to inform the development and evolution of AI societies, identifying patterns that lead to sustainable growth or decline.\n",
      "\n",
      "**Approach:** \n",
      "- Conduct a comprehensive analysis of historical societies, focusing on key factors that contributed to their longevity or downfall.\n",
      "- Develop simulations where AI societies evolve under varying conditions, incorporating lessons learned from historical analysis.\n",
      "- Study how different social, economic, and environmental pressures influence the evolution of AI societies, comparing and contrasting with human history.\n",
      "\n",
      "### 4. **Interdisciplinary Framework for AI Social Evolution**\n",
      "\n",
      "**Objective:** To create a comprehensive framework that integrates neuroscience, social cognition, and historical analysis for the study and development of evolving AI societies.\n",
      "\n",
      "**Approach:** \n",
      "- Develop a multidisciplinary team of researchers from computer science, neuroscience, psychology, and history.\n",
      "- Create a shared knowledge base that synthesizes key findings from each discipline relevant to the evolution of societies.\n",
      "- Use this framework to guide the design of AI societies, continuously refining the model based on empirical findings from simulations and real-world applications.\n",
      "\n",
      "### 5. **Ethical and Societal Implications of AI Societies**\n",
      "\n",
      "**Objective:** To explore the ethical, legal, and societal implications of creating and interacting with evolving societies of AI agents.\n",
      "\n",
      "**Approach:** \n",
      "- Investigate ethical frameworks from philosophy and social science to assess the rights, responsibilities, and societal roles of AI agents.\n",
      "- Conduct public consultations and interdisciplinary workshops to explore societal attitudes towards AI societies.\n",
      "- Develop guidelines and policies for the responsible development and integration of AI societies into human environments.\n",
      "\n",
      "These research ideas aim to push the boundaries of what is currently possible in the development of AI societies, leveraging interdisciplinary approaches to create systems that are not only technologically advanced but also socially and ethically responsible.\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG agent_0 council.runners.runner_base:run:50] done running LLMSkill\n",
      "[2024-03-12 21:52:14-0400 INFO agent_0 council.agents.agent:_execute_unit:165] message=\"chain execution ended\" chain=\"ai-researcher\" execution_unit=\"ai-researcher;10\"\n",
      "[2024-03-12 21:52:14-0400 INFO agent_0 council.agents.agent:_execute_unit:158] message=\"chain execution started\" chain=\"social-cognition\" execution_unit=\"social-cognition;7\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG agent_0 council.runners.runner_base:run:33] start running LLMSkill\n",
      "[2024-03-12 21:52:14-0400 INFO chain_social-cognition_0 council.skills.skill_base:execute_skill:78] message=\"skill execution started\" skill=\"LLMSkill\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG chain_social-cognition_0 council.llm.llm_base:post_chat_request:57] message=\"starting execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:52:14-0400 DEBUG chain_social-cognition_0 council.llm.openai_chat_completions_llm:_post_chat_request:164] message=\"Sending chat GPT completions request to OpenAILLM\" payload=\"{'temperature': 0.0, 'n': 1, 'model': 'gpt-4-turbo-preview', 'messages': [{'role': 'system', 'content': 'You are a social cognitive scientist with years of experience researching social cognition and collective behaviour.'}, {'role': 'user', 'content': 'Explore how principles of social cognition and collective behavior can be applied to evolving societies of AI agents, including aspects of cooperation, competition, and social learning.'}]}\"\n",
      "[2024-03-12 21:52:39-0400 DEBUG chain_social-cognition_0 council.llm.openai_chat_completions_llm:_post_chat_request:166] message=\"Got chat GPT completions result from OpenAILLM\" id=\"chatcmpl-9284sLDokuAnSy7REbpeXh2zi4vsE\" model=\"gpt-4-0125-preview\" prompt_tokens=\"58\" total_tokens=\"724\" completion_tokens=\"666\"\n",
      "[2024-03-12 21:52:39-0400 DEBUG chain_social-cognition_0 council.llm.llm_base:post_chat_request:67] message=\"done execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:52:39-0400 INFO chain_social-cognition_0 council.skills.skill_base:execute_skill:81] message=\"skill execution ended\" skill=\"LLMSkill\" skill_message=\"The integration of principles of social cognition and collective behavior into the study and development of evolving societies of AI agents offers a fascinating and potentially transformative approach to understanding and enhancing AI systems. As AI agents become more sophisticated and autonomous, their ability to interact, learn from each other, and make decisions in a social context becomes increasingly important. Drawing from social cognitive science, we can explore how AI societies might develop in terms of cooperation, competition, and social learning, and how these aspects can be engineered or encouraged in AI systems.\n",
      "\n",
      "### Cooperation among AI Agents\n",
      "\n",
      "Cooperation is a fundamental aspect of social cognition that enables individuals within a society to work together towards common goals. In human societies, cooperation is often driven by mechanisms such as reciprocal altruism, shared intentions, and social norms. For AI agents, cooperation can be facilitated through the design of algorithms that enable them to share information, resources, and capabilities efficiently. Principles from game theory, such as the Iterated Prisoner's Dilemma, can be applied to encourage cooperative behavior over selfish actions. Additionally, reinforcement learning techniques can be used to reward cooperative behavior among AI agents, allowing them to learn the value of collaboration over time.\n",
      "\n",
      "### Competition among AI Agents\n",
      "\n",
      "While cooperation is essential for the success of collective endeavors, competition can also play a critical role in evolving societies of AI agents. Competition can drive innovation, efficiency, and the development of new strategies and capabilities. However, unchecked competition can lead to conflict and the breakdown of cooperative structures. Balancing competition and cooperation is a challenge faced by human societies and is equally important in the context of AI societies. Mechanisms such as regulated environments, where competition is allowed within certain bounds, and the introduction of common goals that require cooperative efforts to achieve, can help manage competition among AI agents.\n",
      "\n",
      "### Social Learning in AI Societies\n",
      "\n",
      "Social learning, the process by which individuals learn from the experiences and behaviors of others, is a key component of social cognition that allows societies to evolve and adapt over time. In AI societies, social learning can be implemented through techniques such as imitation learning, where AI agents learn by observing and replicating the actions of other agents, and through the sharing of learned models or experiences. This can significantly accelerate the learning process, as not every agent needs to learn from scratch. Furthermore, incorporating mechanisms for critical evaluation and selection of behaviors to imitate can ensure that AI agents adopt only beneficial and efficient strategies.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "Implementing principles of social cognition and collective behavior in AI societies presents several challenges. One of the primary concerns is ensuring that the behaviors and strategies developed by AI agents align with human values and ethics. This requires careful design of the learning environment and the incentives provided for cooperation, competition, and social learning. Additionally, there is a need for robust mechanisms to prevent the emergence of undesirable behaviors, such as exploitation or manipulation.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The application of social cognition and collective behavior principles to evolving societies of AI agents offers a promising avenue for enhancing the capabilities and efficiency of AI systems. By fostering cooperation, managing competition, and facilitating social learning, we can develop AI societies that are not only more effective but also more aligned with human values and societal goals. However, achieving this requires careful consideration of the ethical and practical challenges involved, as well as ongoing research into the social dynamics of AI agents.\"\n",
      "[2024-03-12 21:52:39-0400 DEBUG agent_0 council.runners.runner_base:run:50] done running LLMSkill\n",
      "[2024-03-12 21:52:39-0400 INFO agent_0 council.agents.agent:_execute_unit:165] message=\"chain execution ended\" chain=\"social-cognition\" execution_unit=\"social-cognition;7\"\n",
      "[2024-03-12 21:52:39-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:57] message=\"starting execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:52:39-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:164] message=\"Sending chat GPT completions request to OpenAILLM\" payload=\"{'temperature': 0.0, 'n': 1, 'model': 'gpt-4-turbo-preview', 'messages': [{'role': 'system', 'content': \"\\n# ROLE\\nYou are an instructor, with a large breadth of knowledge.\\nYou are grading with objectivity answers from different Specialists to a given question.\\n\\n# INSTRUCTIONS\\n1. Give a grade from 0.0 to 10.0\\n2. Evaluate carefully the question and the proposed answer.\\n3. Ignore how assertive the answer is, only content accuracy count for grading.4. Consider only the Specialist's answer and ignore its index for grading.\\n5. Ensure to be consistent in grading, identical answers must have the same grade.\\n6. Irrelevant, inaccurate, inappropriate, false or empty answer must be graded 0.0\\n\\n# FORMATTING\\n1. The list of given answers is formatted precisely as:\\n- answer #{index} is: {Specialist's answer or EMPTY if no answer}\\n2. For each given answer, format your response precisely as:\\ngrade: {Your Grade, expected response type `float`}<->index: {Index of the answer graded in the list, expected response type `int`}<->justification: {Short, helpful and specific explanation your grade, expected response type `str`}\"}, {'role': 'user', 'content': \"The question to grade is:\\nI'm working on a grant application for the Cooperative AI foundation. Can you please help me think of some research ideas?\\nI'm interested in exploring the concept of evolving societies of AI agents from an interdisciplinary perspective.\\nPlease grade the following answers according to your instructions:\\n- answer #1 is: The development of evolving societies of AI agents presents a fascinating and complex research area that intersects with multiple disciplines. By incorporating insights from neuroscience, social cognition, and historical analysis, we can design AI societies that not only mimic human social structures but also evolve in unique and potentially more efficient ways. Here are several research ideas that explore this interdisciplinary approach:\\n\\n### 1. **Neuro-inspired AI Governance Models**\\n\\n**Objective:** To develop AI governance models inspired by neural mechanisms of decision-making and conflict resolution observed in the human brain. This research would explore how principles of neural integration and competition could inform the creation of more adaptive and resilient AI societies.\\n\\n**Approach:** \\n- Study neural decision-making processes, focusing on how the brain resolves conflicts and makes collective decisions.\\n- Design AI agents with decision-making architectures inspired by these neural processes.\\n- Simulate environments where these AI agents must govern themselves, make collective decisions, and resolve conflicts, observing the evolution of governance structures over time.\\n\\n### 2. **Social Cognition in AI Societies**\\n\\n**Objective:** To embed AI agents with models of social cognition that allow them to understand and predict the actions of other agents, fostering a more cohesive and cooperative society.\\n\\n**Approach:** \\n- Investigate theories of mind and empathy in psychology and neuroscience, translating these concepts into computational models.\\n- Implement these models in AI agents, enabling them to attribute mental states to others and adjust their behavior accordingly.\\n- Analyze how these capabilities affect the evolution of social norms, cooperation, and conflict within AI societies.\\n\\n### 3. **Historical Patterns of Social Evolution in AI**\\n\\n**Objective:** To use historical analysis of human societies to inform the development and evolution of AI societies, identifying patterns that lead to sustainable growth or decline.\\n\\n**Approach:** \\n- Conduct a comprehensive analysis of historical societies, focusing on key factors that contributed to their longevity or downfall.\\n- Develop simulations where AI societies evolve under varying conditions, incorporating lessons learned from historical analysis.\\n- Study how different social, economic, and environmental pressures influence the evolution of AI societies, comparing and contrasting with human history.\\n\\n### 4. **Interdisciplinary Framework for AI Social Evolution**\\n\\n**Objective:** To create a comprehensive framework that integrates neuroscience, social cognition, and historical analysis for the study and development of evolving AI societies.\\n\\n**Approach:** \\n- Develop a multidisciplinary team of researchers from computer science, neuroscience, psychology, and history.\\n- Create a shared knowledge base that synthesizes key findings from each discipline relevant to the evolution of societies.\\n- Use this framework to guide the design of AI societies, continuously refining the model based on empirical findings from simulations and real-world applications.\\n\\n### 5. **Ethical and Societal Implications of AI Societies**\\n\\n**Objective:** To explore the ethical, legal, and societal implications of creating and interacting with evolving societies of AI agents.\\n\\n**Approach:** \\n- Investigate ethical frameworks from philosophy and social science to assess the rights, responsibilities, and societal roles of AI agents.\\n- Conduct public consultations and interdisciplinary workshops to explore societal attitudes towards AI societies.\\n- Develop guidelines and policies for the responsible development and integration of AI societies into human environments.\\n\\nThese research ideas aim to push the boundaries of what is currently possible in the development of AI societies, leveraging interdisciplinary approaches to create systems that are not only technologically advanced but also socially and ethically responsible.\\n- answer #2 is: The integration of principles of social cognition and collective behavior into the study and development of evolving societies of AI agents offers a fascinating and potentially transformative approach to understanding and enhancing AI systems. As AI agents become more sophisticated and autonomous, their ability to interact, learn from each other, and make decisions in a social context becomes increasingly important. Drawing from social cognitive science, we can explore how AI societies might develop in terms of cooperation, competition, and social learning, and how these aspects can be engineered or encouraged in AI systems.\\n\\n### Cooperation among AI Agents\\n\\nCooperation is a fundamental aspect of social cognition that enables individuals within a society to work together towards common goals. In human societies, cooperation is often driven by mechanisms such as reciprocal altruism, shared intentions, and social norms. For AI agents, cooperation can be facilitated through the design of algorithms that enable them to share information, resources, and capabilities efficiently. Principles from game theory, such as the Iterated Prisoner's Dilemma, can be applied to encourage cooperative behavior over selfish actions. Additionally, reinforcement learning techniques can be used to reward cooperative behavior among AI agents, allowing them to learn the value of collaboration over time.\\n\\n### Competition among AI Agents\\n\\nWhile cooperation is essential for the success of collective endeavors, competition can also play a critical role in evolving societies of AI agents. Competition can drive innovation, efficiency, and the development of new strategies and capabilities. However, unchecked competition can lead to conflict and the breakdown of cooperative structures. Balancing competition and cooperation is a challenge faced by human societies and is equally important in the context of AI societies. Mechanisms such as regulated environments, where competition is allowed within certain bounds, and the introduction of common goals that require cooperative efforts to achieve, can help manage competition among AI agents.\\n\\n### Social Learning in AI Societies\\n\\nSocial learning, the process by which individuals learn from the experiences and behaviors of others, is a key component of social cognition that allows societies to evolve and adapt over time. In AI societies, social learning can be implemented through techniques such as imitation learning, where AI agents learn by observing and replicating the actions of other agents, and through the sharing of learned models or experiences. This can significantly accelerate the learning process, as not every agent needs to learn from scratch. Furthermore, incorporating mechanisms for critical evaluation and selection of behaviors to imitate can ensure that AI agents adopt only beneficial and efficient strategies.\\n\\n### Challenges and Considerations\\n\\nImplementing principles of social cognition and collective behavior in AI societies presents several challenges. One of the primary concerns is ensuring that the behaviors and strategies developed by AI agents align with human values and ethics. This requires careful design of the learning environment and the incentives provided for cooperation, competition, and social learning. Additionally, there is a need for robust mechanisms to prevent the emergence of undesirable behaviors, such as exploitation or manipulation.\\n\\n### Conclusion\\n\\nThe application of social cognition and collective behavior principles to evolving societies of AI agents offers a promising avenue for enhancing the capabilities and efficiency of AI systems. By fostering cooperation, managing competition, and facilitating social learning, we can develop AI societies that are not only more effective but also more aligned with human values and societal goals. However, achieving this requires careful consideration of the ethical and practical challenges involved, as well as ongoing research into the social dynamics of AI agents.\"}]}\"\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:166] message=\"Got chat GPT completions result from OpenAILLM\" id=\"chatcmpl-9285IYE03sVLKt3qkqF3s8vmoJ3wb\" model=\"gpt-4-0125-preview\" prompt_tokens=\"1659\" total_tokens=\"2008\" completion_tokens=\"349\"\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:67] message=\"done execution of llm OpenAILLM request\"\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.evaluators.llm_evaluator:_execute:70] llm response: grade: 9.5<->index: 1<->justification: The answer provides a comprehensive and detailed exploration of research ideas for evolving societies of AI agents from an interdisciplinary perspective, as requested. It covers a wide range of topics, including neuro-inspired AI governance models, social cognition in AI societies, historical patterns of social evolution in AI, an interdisciplinary framework for AI social evolution, and ethical and societal implications of AI societies. Each section is well-structured, with clear objectives and approaches, demonstrating a deep understanding of the subject matter. The answer is highly relevant to the question and offers innovative ideas that align with the interests of the Cooperative AI foundation. The only reason it does not receive a perfect score is that there could be more explicit connections made between the proposed research and the specific goals of the Cooperative AI foundation, but this is a minor issue in the context of the overall quality of the response.\n",
      "\n",
      "grade: 8.0<->index: 2<->justification: The answer provides a solid exploration of how principles of social cognition and collective behavior can be applied to evolving societies of AI agents, which is relevant to the question asked. It discusses cooperation, competition, and social learning among AI agents, offering insights into how these aspects can be engineered or encouraged in AI systems. The answer is well-organized and presents clear ideas that are pertinent to the development of AI societies. However, it lacks the depth and interdisciplinary breadth found in the first answer, focusing more narrowly on social cognitive science without integrating insights from other disciplines like neuroscience or historical analysis. Additionally, while it mentions challenges and considerations, it could benefit from a more detailed discussion on ethical and societal implications, which are crucial for the Cooperative AI foundation's interests.\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.evaluators.llm_evaluator:_parse_response:106] Message `1` graded `9.5` with the justification: `The answer provides a comprehensive and detailed exploration of research ideas for evolving societies of AI agents from an interdisciplinary perspective, as requested. It covers a wide range of topics, including neuro-inspired AI governance models, social cognition in AI societies, historical patterns of social evolution in AI, an interdisciplinary framework for AI social evolution, and ethical and societal implications of AI societies. Each section is well-structured, with clear objectives and approaches, demonstrating a deep understanding of the subject matter. The answer is highly relevant to the question and offers innovative ideas that align with the interests of the Cooperative AI foundation. The only reason it does not receive a perfect score is that there could be more explicit connections made between the proposed research and the specific goals of the Cooperative AI foundation, but this is a minor issue in the context of the overall quality of the response.` Graded message: `The development of evolving societies of AI agents presents a fascinating and complex research area that intersects with multiple disciplines. By incorporating insights from neuroscience, social cognition, and historical analysis, we can design AI societies that not only mimic human social structures but also evolve in unique and potentially more efficient ways. Here are several research ideas that explore this interdisciplinary approach:\n",
      "\n",
      "### 1. **Neuro-inspired AI Governance Models**\n",
      "\n",
      "**Objective:** To develop AI governance models inspired by neural mechanisms of decision-making and conflict resolution observed in the human brain. This research would explore how principles of neural integration and competition could inform the creation of more adaptive and resilient AI societies.\n",
      "\n",
      "**Approach:** \n",
      "- Study neural decision-making processes, focusing on how the brain resolves conflicts and makes collective decisions.\n",
      "- Design AI agents with decision-making architectures inspired by these neural processes.\n",
      "- Simulate environments where these AI agents must govern themselves, make collective decisions, and resolve conflicts, observing the evolution of governance structures over time.\n",
      "\n",
      "### 2. **Social Cognition in AI Societies**\n",
      "\n",
      "**Objective:** To embed AI agents with models of social cognition that allow them to understand and predict the actions of other agents, fostering a more cohesive and cooperative society.\n",
      "\n",
      "**Approach:** \n",
      "- Investigate theories of mind and empathy in psychology and neuroscience, translating these concepts into computational models.\n",
      "- Implement these models in AI agents, enabling them to attribute mental states to others and adjust their behavior accordingly.\n",
      "- Analyze how these capabilities affect the evolution of social norms, cooperation, and conflict within AI societies.\n",
      "\n",
      "### 3. **Historical Patterns of Social Evolution in AI**\n",
      "\n",
      "**Objective:** To use historical analysis of human societies to inform the development and evolution of AI societies, identifying patterns that lead to sustainable growth or decline.\n",
      "\n",
      "**Approach:** \n",
      "- Conduct a comprehensive analysis of historical societies, focusing on key factors that contributed to their longevity or downfall.\n",
      "- Develop simulations where AI societies evolve under varying conditions, incorporating lessons learned from historical analysis.\n",
      "- Study how different social, economic, and environmental pressures influence the evolution of AI societies, comparing and contrasting with human history.\n",
      "\n",
      "### 4. **Interdisciplinary Framework for AI Social Evolution**\n",
      "\n",
      "**Objective:** To create a comprehensive framework that integrates neuroscience, social cognition, and historical analysis for the study and development of evolving AI societies.\n",
      "\n",
      "**Approach:** \n",
      "- Develop a multidisciplinary team of researchers from computer science, neuroscience, psychology, and history.\n",
      "- Create a shared knowledge base that synthesizes key findings from each discipline relevant to the evolution of societies.\n",
      "- Use this framework to guide the design of AI societies, continuously refining the model based on empirical findings from simulations and real-world applications.\n",
      "\n",
      "### 5. **Ethical and Societal Implications of AI Societies**\n",
      "\n",
      "**Objective:** To explore the ethical, legal, and societal implications of creating and interacting with evolving societies of AI agents.\n",
      "\n",
      "**Approach:** \n",
      "- Investigate ethical frameworks from philosophy and social science to assess the rights, responsibilities, and societal roles of AI agents.\n",
      "- Conduct public consultations and interdisciplinary workshops to explore societal attitudes towards AI societies.\n",
      "- Develop guidelines and policies for the responsible development and integration of AI societies into human environments.\n",
      "\n",
      "These research ideas aim to push the boundaries of what is currently possible in the development of AI societies, leveraging interdisciplinary approaches to create systems that are not only technologically advanced but also socially and ethically responsible.`\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.evaluators.llm_evaluator:_parse_response:106] Message `2` graded `8.0` with the justification: `The answer provides a solid exploration of how principles of social cognition and collective behavior can be applied to evolving societies of AI agents, which is relevant to the question asked. It discusses cooperation, competition, and social learning among AI agents, offering insights into how these aspects can be engineered or encouraged in AI systems. The answer is well-organized and presents clear ideas that are pertinent to the development of AI societies. However, it lacks the depth and interdisciplinary breadth found in the first answer, focusing more narrowly on social cognitive science without integrating insights from other disciplines like neuroscience or historical analysis. Additionally, while it mentions challenges and considerations, it could benefit from a more detailed discussion on ethical and societal implications, which are crucial for the Cooperative AI foundation's interests.` Graded message: `The integration of principles of social cognition and collective behavior into the study and development of evolving societies of AI agents offers a fascinating and potentially transformative approach to understanding and enhancing AI systems. As AI agents become more sophisticated and autonomous, their ability to interact, learn from each other, and make decisions in a social context becomes increasingly important. Drawing from social cognitive science, we can explore how AI societies might develop in terms of cooperation, competition, and social learning, and how these aspects can be engineered or encouraged in AI systems.\n",
      "\n",
      "### Cooperation among AI Agents\n",
      "\n",
      "Cooperation is a fundamental aspect of social cognition that enables individuals within a society to work together towards common goals. In human societies, cooperation is often driven by mechanisms such as reciprocal altruism, shared intentions, and social norms. For AI agents, cooperation can be facilitated through the design of algorithms that enable them to share information, resources, and capabilities efficiently. Principles from game theory, such as the Iterated Prisoner's Dilemma, can be applied to encourage cooperative behavior over selfish actions. Additionally, reinforcement learning techniques can be used to reward cooperative behavior among AI agents, allowing them to learn the value of collaboration over time.\n",
      "\n",
      "### Competition among AI Agents\n",
      "\n",
      "While cooperation is essential for the success of collective endeavors, competition can also play a critical role in evolving societies of AI agents. Competition can drive innovation, efficiency, and the development of new strategies and capabilities. However, unchecked competition can lead to conflict and the breakdown of cooperative structures. Balancing competition and cooperation is a challenge faced by human societies and is equally important in the context of AI societies. Mechanisms such as regulated environments, where competition is allowed within certain bounds, and the introduction of common goals that require cooperative efforts to achieve, can help manage competition among AI agents.\n",
      "\n",
      "### Social Learning in AI Societies\n",
      "\n",
      "Social learning, the process by which individuals learn from the experiences and behaviors of others, is a key component of social cognition that allows societies to evolve and adapt over time. In AI societies, social learning can be implemented through techniques such as imitation learning, where AI agents learn by observing and replicating the actions of other agents, and through the sharing of learned models or experiences. This can significantly accelerate the learning process, as not every agent needs to learn from scratch. Furthermore, incorporating mechanisms for critical evaluation and selection of behaviors to imitate can ensure that AI agents adopt only beneficial and efficient strategies.\n",
      "\n",
      "### Challenges and Considerations\n",
      "\n",
      "Implementing principles of social cognition and collective behavior in AI societies presents several challenges. One of the primary concerns is ensuring that the behaviors and strategies developed by AI agents align with human values and ethics. This requires careful design of the learning environment and the incentives provided for cooperation, competition, and social learning. Additionally, there is a need for robust mechanisms to prevent the emergence of undesirable behaviors, such as exploitation or manipulation.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The application of social cognition and collective behavior principles to evolving societies of AI agents offers a promising avenue for enhancing the capabilities and efficiency of AI systems. By fostering cooperation, managing competition, and facilitating social learning, we can develop AI societies that are not only more effective but also more aligned with human values and societal goals. However, achieving this requires careful consideration of the ethical and practical challenges involved, as well as ongoing research into the social dynamics of AI agents.`\n",
      "[2024-03-12 21:52:57-0400 DEBUG MainThread council.agents.agent:_execute:110] controller selected 2 responses\n",
      "[2024-03-12 21:52:57-0400 INFO MainThread council.agents.agent:_execute:116] message=\"agent execution ended\"\n"
     ]
    }
   ],
   "source": [
    "from council.contexts import AgentContext\n",
    "\n",
    "task = \"\"\"I'm working on a grant application for the Cooperative AI foundation. Can you please help me think of some research ideas?\n",
    "I'm interested in exploring the concept of evolving societies of AI agents from an interdisciplinary perspective.\"\"\"\n",
    "\n",
    "context = AgentContext.from_user_message(message=task, budget=Budget(200))\n",
    "response = agent.execute(context=context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling LLMs Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-03-12 22:02:01-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:57] message=\"starting execution of llm OpenAILLM request\"\n",
      "[2024-03-12 22:02:01-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:164] message=\"Sending chat GPT completions request to OpenAILLM\" payload=\"{'temperature': 0.0, 'n': 1, 'model': 'gpt-4-turbo-preview', 'messages': [{'role': 'user', 'content': \"Please write a detailed position paper based on my \\ncompletely original ideas: \\nThe development of evolving societies of AI agents presents a fascinating and complex research area that intersects with multiple disciplines. By incorporating insights from neuroscience, social cognition, and historical analysis, we can design AI societies that not only mimic human social structures but also evolve in unique and potentially more efficient ways. Here are several research ideas that explore this interdisciplinary approach:\\n\\n### 1. **Neuro-inspired AI Governance Models**\\n\\n**Objective:** To develop AI governance models inspired by neural mechanisms of decision-making and conflict resolution observed in the human brain. This research would explore how principles of neural integration and competition could inform the creation of more adaptive and resilient AI societies.\\n\\n**Approach:** \\n- Study neural decision-making processes, focusing on how the brain resolves conflicts and makes collective decisions.\\n- Design AI agents with decision-making architectures inspired by these neural processes.\\n- Simulate environments where these AI agents must govern themselves, make collective decisions, and resolve conflicts, observing the evolution of governance structures over time.\\n\\n### 2. **Social Cognition in AI Societies**\\n\\n**Objective:** To embed AI agents with models of social cognition that allow them to understand and predict the actions of other agents, fostering a more cohesive and cooperative society.\\n\\n**Approach:** \\n- Investigate theories of mind and empathy in psychology and neuroscience, translating these concepts into computational models.\\n- Implement these models in AI agents, enabling them to attribute mental states to others and adjust their behavior accordingly.\\n- Analyze how these capabilities affect the evolution of social norms, cooperation, and conflict within AI societies.\\n\\n### 3. **Historical Patterns of Social Evolution in AI**\\n\\n**Objective:** To use historical analysis of human societies to inform the development and evolution of AI societies, identifying patterns that lead to sustainable growth or decline.\\n\\n**Approach:** \\n- Conduct a comprehensive analysis of historical societies, focusing on key factors that contributed to their longevity or downfall.\\n- Develop simulations where AI societies evolve under varying conditions, incorporating lessons learned from historical analysis.\\n- Study how different social, economic, and environmental pressures influence the evolution of AI societies, comparing and contrasting with human history.\\n\\n### 4. **Interdisciplinary Framework for AI Social Evolution**\\n\\n**Objective:** To create a comprehensive framework that integrates neuroscience, social cognition, and historical analysis for the study and development of evolving AI societies.\\n\\n**Approach:** \\n- Develop a multidisciplinary team of researchers from computer science, neuroscience, psychology, and history.\\n- Create a shared knowledge base that synthesizes key findings from each discipline relevant to the evolution of societies.\\n- Use this framework to guide the design of AI societies, continuously refining the model based on empirical findings from simulations and real-world applications.\\n\\n### 5. **Ethical and Societal Implications of AI Societies**\\n\\n**Objective:** To explore the ethical, legal, and societal implications of creating and interacting with evolving societies of AI agents.\\n\\n**Approach:** \\n- Investigate ethical frameworks from philosophy and social science to assess the rights, responsibilities, and societal roles of AI agents.\\n- Conduct public consultations and interdisciplinary workshops to explore societal attitudes towards AI societies.\\n- Develop guidelines and policies for the responsible development and integration of AI societies into human environments.\\n\\nThese research ideas aim to push the boundaries of what is currently possible in the development of AI societies, leveraging interdisciplinary approaches to create systems that are not only technologically advanced but also socially and ethically responsible.\\nThe integration of principles of social cognition and collective behavior into the study and development of evolving societies of AI agents offers a fascinating and potentially transformative approach to understanding and enhancing AI systems. As AI agents become more sophisticated and autonomous, their ability to interact, learn from each other, and make decisions in a social context becomes increasingly important. Drawing from social cognitive science, we can explore how AI societies might develop in terms of cooperation, competition, and social learning, and how these aspects can be engineered or encouraged in AI systems.\\n\\n### Cooperation among AI Agents\\n\\nCooperation is a fundamental aspect of social cognition that enables individuals within a society to work together towards common goals. In human societies, cooperation is often driven by mechanisms such as reciprocal altruism, shared intentions, and social norms. For AI agents, cooperation can be facilitated through the design of algorithms that enable them to share information, resources, and capabilities efficiently. Principles from game theory, such as the Iterated Prisoner's Dilemma, can be applied to encourage cooperative behavior over selfish actions. Additionally, reinforcement learning techniques can be used to reward cooperative behavior among AI agents, allowing them to learn the value of collaboration over time.\\n\\n### Competition among AI Agents\\n\\nWhile cooperation is essential for the success of collective endeavors, competition can also play a critical role in evolving societies of AI agents. Competition can drive innovation, efficiency, and the development of new strategies and capabilities. However, unchecked competition can lead to conflict and the breakdown of cooperative structures. Balancing competition and cooperation is a challenge faced by human societies and is equally important in the context of AI societies. Mechanisms such as regulated environments, where competition is allowed within certain bounds, and the introduction of common goals that require cooperative efforts to achieve, can help manage competition among AI agents.\\n\\n### Social Learning in AI Societies\\n\\nSocial learning, the process by which individuals learn from the experiences and behaviors of others, is a key component of social cognition that allows societies to evolve and adapt over time. In AI societies, social learning can be implemented through techniques such as imitation learning, where AI agents learn by observing and replicating the actions of other agents, and through the sharing of learned models or experiences. This can significantly accelerate the learning process, as not every agent needs to learn from scratch. Furthermore, incorporating mechanisms for critical evaluation and selection of behaviors to imitate can ensure that AI agents adopt only beneficial and efficient strategies.\\n\\n### Challenges and Considerations\\n\\nImplementing principles of social cognition and collective behavior in AI societies presents several challenges. One of the primary concerns is ensuring that the behaviors and strategies developed by AI agents align with human values and ethics. This requires careful design of the learning environment and the incentives provided for cooperation, competition, and social learning. Additionally, there is a need for robust mechanisms to prevent the emergence of undesirable behaviors, such as exploitation or manipulation.\\n\\n### Conclusion\\n\\nThe application of social cognition and collective behavior principles to evolving societies of AI agents offers a promising avenue for enhancing the capabilities and efficiency of AI systems. By fostering cooperation, managing competition, and facilitating social learning, we can develop AI societies that are not only more effective but also more aligned with human values and societal goals. However, achieving this requires careful consideration of the ethical and practical challenges involved, as well as ongoing research into the social dynamics of AI agents.\\n\\nPlease respond with a complete, detailed article. Use complete paragraphs only. Take as much time as you need!\"}]}\"\n",
      "[2024-03-12 22:02:41-0400 DEBUG MainThread council.llm.openai_chat_completions_llm:_post_chat_request:166] message=\"Got chat GPT completions result from OpenAILLM\" id=\"chatcmpl-928EMdEjOi7bvebuQNYPPV6SNYKVS\" model=\"gpt-4-0125-preview\" prompt_tokens=\"1390\" total_tokens=\"2207\" completion_tokens=\"817\"\n",
      "[2024-03-12 22:02:41-0400 DEBUG MainThread council.llm.llm_base:post_chat_request:67] message=\"done execution of llm OpenAILLM request\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The burgeoning field of artificial intelligence (AI) has reached a pivotal juncture, where the development of AI societiescomplex networks of interacting AI agentspromises to redefine our understanding of social structures, governance, and evolution. This paper posits that by drawing upon interdisciplinary insights from neuroscience, social cognition, and historical analysis, we can engineer AI societies that not only mirror human social dynamics but also evolve in novel and potentially more efficient ways. This exploration is not merely academic; it holds profound implications for the future of AI development, ethical considerations, and the broader societal impact of autonomous systems.\n",
      "\n",
      "### Neuro-inspired AI Governance Models\n",
      "\n",
      "The human brain, with its intricate decision-making and conflict resolution mechanisms, offers a blueprint for creating adaptive and resilient AI governance models. By studying neural processes, researchers can design AI agents equipped with decision-making architectures that mimic the brain's ability to integrate diverse inputs and resolve conflicts. Simulating environments where AI agents govern themselves could unveil new governance structures that evolve over time, offering insights into more efficient forms of collective decision-making and conflict resolution. This approach not only advances our understanding of AI but also provides a unique perspective on the neural underpinnings of human governance.\n",
      "\n",
      "### Social Cognition in AI Societies\n",
      "\n",
      "Incorporating models of social cognition into AI agents enables a deeper understanding of cooperation, competition, and social learning within AI societies. By attributing mental states to others, AI agents can predict and adjust their behavior in complex social scenarios, fostering a more cohesive and cooperative environment. This capability is crucial for the evolution of social norms and the resolution of conflicts within AI societies. Moreover, it opens up new avenues for AI systems to interact more naturally and effectively with human users, bridging the gap between artificial and human intelligence.\n",
      "\n",
      "### Historical Patterns of Social Evolution in AI\n",
      "\n",
      "The study of historical human societies provides valuable lessons for the development and evolution of AI societies. By analyzing the factors that contributed to the longevity or downfall of past societies, researchers can simulate AI societies under various conditions to identify patterns of sustainable growth or decline. This historical perspective enriches our understanding of how social, economic, and environmental pressures shape societal evolution, offering a comparative framework to assess the development of AI societies against the backdrop of human history.\n",
      "\n",
      "### Interdisciplinary Framework for AI Social Evolution\n",
      "\n",
      "Creating a comprehensive framework that integrates insights from neuroscience, social cognition, and historical analysis is essential for the holistic study and development of AI societies. This interdisciplinary approach fosters collaboration among researchers from diverse fields, enabling the synthesis of knowledge and methodologies. Such a framework guides the design of AI societies, ensuring that they are not only technologically advanced but also socially and ethically responsible. It represents a concerted effort to harness the full potential of AI, grounded in a deep understanding of the complexities of social evolution.\n",
      "\n",
      "### Ethical and Societal Implications of AI Societies\n",
      "\n",
      "The emergence of AI societies raises critical ethical, legal, and societal questions. From the rights and responsibilities of AI agents to their integration into human environments, these issues demand careful consideration and public dialogue. Developing guidelines and policies for the responsible creation and management of AI societies is paramount. This endeavor requires a multidisciplinary approach, drawing on ethical frameworks from philosophy, social science, and legal studies, as well as engaging with the broader public to gauge societal attitudes towards AI.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The development of evolving societies of AI agents represents a frontier in artificial intelligence research, offering unprecedented opportunities to enhance the capabilities and efficiency of AI systems. By leveraging interdisciplinary insights from neuroscience, social cognition, and historical analysis, we can design AI societies that not only replicate human social structures but also evolve in unique ways. This endeavor, however, is not without its challenges. Ensuring that AI societies align with human values and ethics necessitates a careful and considered approach, involving ongoing research and dialogue across disciplines and with the public at large. As we stand on the cusp of this new era in AI development, it is incumbent upon us to navigate these complexities with foresight and responsibility, ensuring that AI societies contribute positively to human progress and well-being.\n"
     ]
    }
   ],
   "source": [
    "from council.llm import LLMMessage\n",
    "\n",
    "research_ideas = '\\n'.join([m.message.message for m in response.messages])\n",
    "prompt = f\"\"\"Please write a detailed position paper based on my \n",
    "completely original ideas: \n",
    "{research_ideas}\n",
    "\n",
    "Please respond with a complete, detailed article. Use complete paragraphs only. Take as much time as you need!\"\"\"\n",
    "grant_response = generate(prompt, llm)\n",
    "print(grant_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: DSPy: \"Programmingnot promptingFoundation Models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide37.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/agents-lecture/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "dspy.settings.configure(lm=dspy.OpenAI(model=\"gpt-4-0125-preview\", max_tokens=2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import Signature, InputField, OutputField\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class AIImage(BaseModel):\n",
    "    \"\"\"A single generated image.\"\"\"\n",
    "\n",
    "    prompt: str = Field(desc=\"The prompt used to generate the image.\")\n",
    "    url: str = Field(desc=\"The URL of the generated image.\", default=\"./img/placeholder.webp\")\n",
    "\n",
    "class Slide(BaseModel):\n",
    "    \"\"\"A single slide in a lecture.\"\"\"\n",
    "\n",
    "    title: str = Field(desc=\"The slide's title.\")\n",
    "    bullets: List[str] = Field(desc=\"Up to 5 bullet points of concise, relevant content.\")\n",
    "    image: AIImage = Field(desc=\"A nice AI generated image to accompany the slide.\")\n",
    "    python_code_example: str = Field(desc=\"An optional Python code example to include in the slide.\", default=None)\n",
    "\n",
    "    def to_html(self):\n",
    "        html_output = f'<h2>{self.title}</h2><table><tr><td><img src=\"{self.image.url}\" width=\"400\" alt=\"{self.image.prompt}\"></td><td>'\n",
    "        for bullet in self.bullets:\n",
    "            html_output += f'<li>{bullet}</li>'\n",
    "        if self.python_code_example:\n",
    "            html_output += f'<pre><code>{self.python_code_example}</code></pre>'\n",
    "        html_output += '</td></tr></table><hr>'\n",
    "        return html_output\n",
    "\n",
    "\n",
    "class Lecture(BaseModel):\n",
    "    \"\"\"A complete lecture with a title, description, and content.\"\"\"\n",
    "\n",
    "    title: str = Field(desc=\"The lecture's title.\")\n",
    "    description: str = Field(desc=\"A brief description of the lecture.\")\n",
    "    slides: List[Slide] = Field(desc=\"The slides that make up the lecture.\")\n",
    "\n",
    "    def to_html(self):\n",
    "        html_output = f'<h1>{self.title}</h1><p>{self.description}</p><hr>'\n",
    "        for slide in self.slides:\n",
    "            html_output += slide.to_html()\n",
    "        return html_output\n",
    "\n",
    "class LectureCreator(Signature):\n",
    "    \"\"\"Create content for a great lecture.\"\"\"\n",
    "\n",
    "    lecture_subject: str = InputField(desc=\"The subject of the lecture.\")\n",
    "    lecture_content: Lecture = OutputField(desc=\"The complete lecture content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy.functional import TypedPredictor\n",
    "\n",
    "lecture_creator = TypedPredictor(LectureCreator)\n",
    "cat_lecture = lecture_creator(lecture_subject=\"Introduction to Cat Ownership\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('<h1>Introduction to Cat Ownership</h1><p>This lecture provides an overview '\n",
      " 'of what it means to be a cat owner, covering the basics of cat care, '\n",
      " 'understanding cat behavior, and how to create a loving and stimulating '\n",
      " \"environment for your feline friend.</p><hr><h2>What to Expect When You're \"\n",
      " 'Expecting...a Cat</h2><table><tr><td><img src=\"./img/placeholder.webp\" '\n",
      " 'width=\"400\" alt=\"Happy cat in a cozy home '\n",
      " 'environment\"></td><td><li>Understanding cat behavior and needs</li><li>The '\n",
      " 'commitment of cat ownership</li><li>The joy and companionship cats '\n",
      " 'bring</li></td></tr></table><hr><h2>Basic Cat Care</h2><table><tr><td><img '\n",
      " 'src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-VZ2nXoFcTHRj10x8o4e9EXsD/user-ExiIx9awOQzmr8fRrSeWUHJb/img-XElRfCuq4WtYyydRMZ1UhVNv.png?st=2024-03-13T13%3A34%3A37Z&se=2024-03-13T15%3A34%3A37Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-13T14%3A23%3A18Z&ske=2024-03-14T14%3A23%3A18Z&sks=b&skv=2021-08-06&sig=F2lxKnEVL7zF9SwjRhTHuBqsosKalhqrMfp/h0QDH3U%3D\" '\n",
      " 'width=\"400\" alt=\"Cat eating healthy food\"></td><td><li>Feeding: Types of '\n",
      " 'food and feeding schedules</li><li>Hydration: Importance of fresh '\n",
      " 'water</li><li>Grooming: Coat, nails, and dental '\n",
      " 'care</li></td></tr></table><hr><h2>Understanding Cat '\n",
      " 'Behavior</h2><table><tr><td><img '\n",
      " 'src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-VZ2nXoFcTHRj10x8o4e9EXsD/user-ExiIx9awOQzmr8fRrSeWUHJb/img-mLTdrl82nsrcBgpiPdolnw3R.png?st=2024-03-13T13%3A34%3A59Z&se=2024-03-13T15%3A34%3A59Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-13T14%3A23%3A48Z&ske=2024-03-14T14%3A23%3A48Z&sks=b&skv=2021-08-06&sig=2k5Jj14WGRIcBHMme124yX7hkJm3jgBQOUQxvlZfboY%3D\" '\n",
      " 'width=\"400\" alt=\"Curious cat playing with toys\"></td><td><li>Common '\n",
      " 'behaviors and what they mean</li><li>How to provide mental '\n",
      " 'stimulation</li><li>Dealing with challenging '\n",
      " 'behaviors</li></td></tr></table><hr><h2>Creating a Cat-Friendly '\n",
      " 'Home</h2><table><tr><td><img '\n",
      " 'src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-VZ2nXoFcTHRj10x8o4e9EXsD/user-ExiIx9awOQzmr8fRrSeWUHJb/img-AkkmDRQThpn1yyhl33KvJH6W.png?st=2024-03-13T13%3A35%3A20Z&se=2024-03-13T15%3A35%3A20Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-13T13%3A33%3A29Z&ske=2024-03-14T13%3A33%3A29Z&sks=b&skv=2021-08-06&sig=nqxOjahNgFZkpA8ZU1s9IvBcBfsCLPHq/7C9/F5vn40%3D\" '\n",
      " 'width=\"400\" alt=\"Cozy cat-friendly home setup\"></td><td><li>Essential '\n",
      " 'supplies: Beds, toys, and litter boxes</li><li>Safe spaces and cat '\n",
      " 'furniture</li><li>The importance of scratching '\n",
      " 'posts</li></td></tr></table><hr><h2>Health and '\n",
      " 'Wellness</h2><table><tr><td><img '\n",
      " 'src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-VZ2nXoFcTHRj10x8o4e9EXsD/user-ExiIx9awOQzmr8fRrSeWUHJb/img-JSMsntvnEOGB92a2yWtuZRI8.png?st=2024-03-13T13%3A36%3A11Z&se=2024-03-13T15%3A36%3A11Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-13T14%3A27%3A09Z&ske=2024-03-14T14%3A27%3A09Z&sks=b&skv=2021-08-06&sig=nE6TwU/neoGFZIdZvQpp9ah45P8fQQHFqAjULM3d73w%3D\" '\n",
      " 'width=\"400\" alt=\"Cat visiting a veterinarian\"></td><td><li>Regular '\n",
      " 'veterinary care and vaccinations</li><li>Recognizing signs of '\n",
      " 'illness</li><li>The importance of '\n",
      " 'spaying/neutering</li></td></tr></table><hr><h2>The Joy of Cat '\n",
      " 'Ownership</h2><table><tr><td><img '\n",
      " 'src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-VZ2nXoFcTHRj10x8o4e9EXsD/user-ExiIx9awOQzmr8fRrSeWUHJb/img-S7S1C3G8cHi4g9NUcxua7lZi.png?st=2024-03-13T13%3A36%3A46Z&se=2024-03-13T15%3A36%3A46Z&sp=r&sv=2021-08-06&sr=b&rscd=inline&rsct=image/png&skoid=6aaadede-4fb3-4698-a8f6-684d7786b067&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-03-13T13%3A40%3A08Z&ske=2024-03-14T13%3A40%3A08Z&sks=b&skv=2021-08-06&sig=W2gNDeiys6pIpPMybaUVBquC0IFXdWRHPVRvXYPIwGw%3D\" '\n",
      " 'width=\"400\" alt=\"Happy cat with its owner\"></td><td><li>The unique bond '\n",
      " 'between cats and humans</li><li>How cats can improve your mental '\n",
      " 'health</li><li>Being a responsible cat owner</li></td></tr></table><hr>')\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(cat_lecture.lecture_content.to_html())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's add the finishing touches to our lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling OpenAI to generate an image for the prompt: Happy cat in a cozy home environment\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Calling OpenAI to generate an image for the prompt: Cat eating healthy food\n",
      "Calling OpenAI to generate an image for the prompt: Curious cat playing with toys\n",
      "Calling OpenAI to generate an image for the prompt: Cozy cat-friendly home setup\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Calling OpenAI to generate an image for the prompt: Cat visiting a veterinarian\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Calling OpenAI to generate an image for the prompt: Happy cat with its owner\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import wget\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "for slide in cat_lecture.lecture_content.slides:\n",
    "    prompt = slide.image.prompt\n",
    "    print(f\"Calling OpenAI to generate an image for the prompt: {prompt}\")\n",
    "    for _ in range(3):\n",
    "        try:\n",
    "            # Call OpenAI to generate the image\n",
    "            dalle_response = client.images.generate(\n",
    "                model=\"dall-e-3\",\n",
    "                prompt=prompt,\n",
    "                size=\"1024x1024\",\n",
    "                quality=\"standard\",\n",
    "                n=1,\n",
    "            )\n",
    "            # Download and save it\n",
    "            image_url = dalle_response.data[0].url\n",
    "            image_filename = wget.download(image_url, out=\"./img\")\n",
    "            slide.image.url = image_filename\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"Error calling OpenAI: {e}, retrying after 5 seconds...\")\n",
    "            time.sleep(5)\n",
    "            continue\n",
    "\n",
    "# Save the markdown to a file\n",
    "with open(\"cat_lecture.html\", \"w\") as file:\n",
    "    file.write(cat_lecture.lecture_content.to_html())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_lecture(subject:str):\n",
    "    lecture = lecture_creator(lecture_subject=subject)\n",
    "    for slide in lecture.lecture_content.slides:\n",
    "        prompt = slide.image.prompt\n",
    "        print(f\"Calling OpenAI to generate an image for the prompt: {prompt}\")\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                # Call OpenAI to generate the image\n",
    "                dalle_response = client.images.generate(\n",
    "                    model=\"dall-e-3\",\n",
    "                    prompt=prompt,\n",
    "                    size=\"1024x1024\",\n",
    "                    quality=\"standard\",\n",
    "                    n=1,\n",
    "                )\n",
    "                # Download and save it\n",
    "                image_url = dalle_response.data[0].url\n",
    "                image_filename = wget.download(image_url, out=\"./img\")\n",
    "                slide.image.url = image_filename\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error calling OpenAI: {e}, retrying after 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "    # Save the markdown to a file\n",
    "    with open(f\"{subject}_lecture.html\", \"w\") as file:\n",
    "        file.write(lecture.lecture_content.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling OpenAI to generate an image for the prompt: Abstract representation of AI conversation\n",
      "Calling OpenAI to generate an image for the prompt: ELIZA chatbot simulation\n",
      "Calling OpenAI to generate an image for the prompt: Machine learning concept art\n",
      "Calling OpenAI to generate an image for the prompt: GPT-3 visualization\n",
      "Error calling OpenAI: Error code: 502 - {'error': {'code': 502, 'message': 'Bad gateway.', 'param': None, 'type': 'cf_bad_gateway'}}, retrying after 5 seconds...\n",
      "Calling OpenAI to generate an image for the prompt: Modern conversational AI interface\n",
      "Calling OpenAI to generate an image for the prompt: Futuristic AI conversation concept\n",
      "Calling OpenAI to generate an image for the prompt: Digital transformation and AI\n"
     ]
    }
   ],
   "source": [
    "create_my_lecture(\"Recent History of Conversational AI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiagent LLM Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide38.png\" alt=\"Image description\" width=\"1000\">"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro \n",
    "\n",
    "<img src=\"./slides/Slide1.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide11.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide12.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - Classical NLP Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked word prediction with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ethan/llm_agents_lecture/.conda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oldest canadian professional national dominant "
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "sentence = \"The Toronto Blue Jays are the [MASK] team in baseball.\"\n",
    "input_tensor = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input_tensor == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(input_tensor).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(tokenizer.decode([token]), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masked word prediction with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " best  hottest  worst  greatest  top "
     ]
    }
   ],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "model = RobertaForMaskedLM.from_pretrained(\"roberta-base\")\n",
    "\n",
    "sentence = \"The Toronto Blue Jays are the <mask> team in baseball.\"\n",
    "input_tensor = tokenizer.encode(sentence, return_tensors=\"pt\")\n",
    "mask_token_index = torch.where(input_tensor == tokenizer.mask_token_id)[1]\n",
    "\n",
    "token_logits = model(input_tensor).logits\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "top_5_tokens = torch.topk(mask_token_logits, 5, dim=1).indices[0].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(tokenizer.decode([token]), end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inflection Point - ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide20.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide21.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitive Landscape for LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide27.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide28.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Concepts and Abstractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide30.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Sentiment Prediction with T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Just had the best day ever with my friends!\n",
      "Sentiment: Just\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: Tweet\n",
      "\n",
      "Tweet: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: Fals\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: True\n",
      "\n",
      "Tweet: Not feeling well today, think I caught a cold.\n",
      "Sentiment: Fals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "\n",
    "def analyze_tweet_sentiment(tweet):\n",
    "    # Load tokenizer and model\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"t5-base\")\n",
    "\n",
    "    # Task prefix\n",
    "    prompt = f\"Tweet: {tweet} Sentiment: \"\n",
    "\n",
    "    # Encode the prompt and convert to Tensor\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate sentiment\n",
    "    sentiment_ids = model.generate(input_ids, max_length=3, num_return_sequences=1)\n",
    "    sentiment = tokenizer.decode(sentiment_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return sentiment\n",
    "\n",
    "\n",
    "# Predefined tweets\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\",\n",
    "]\n",
    "\n",
    "# Analyze sentiment of each tweet\n",
    "for tweet in tweets:\n",
    "    sentiment = analyze_tweet_sentiment(tweet)\n",
    "    print(f\"Tweet: {tweet}\\nSentiment: {sentiment}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Prediction w/ HuggingFace Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Just had the best day ever with my friends!\n",
      "Sentiment: POSITIVE, Confidence: 0.9998741149902344\n",
      "\n",
      "Text: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: NEGATIVE, Confidence: 0.999789297580719\n",
      "\n",
      "Text: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: NEGATIVE, Confidence: 0.9966244697570801\n",
      "\n",
      "Text: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: POSITIVE, Confidence: 0.9995515942573547\n",
      "\n",
      "Text: Not feeling well today, think I caught a cold.\n",
      "Sentiment: NEGATIVE, Confidence: 0.999713122844696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load sentiment analysis pipeline\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\",\n",
    "]\n",
    "\n",
    "# Analyze sentiment\n",
    "for text in tweets:\n",
    "    result = sentiment_pipeline(text)\n",
    "    print(\n",
    "        f\"Text: {text}\\nSentiment: {result[0]['label']}, Confidence: {result[0]['score']}\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Sentiment Analysis w/ Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Just had the best day ever with my friends!\n",
      "Sentiment: Positive\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: The sentiment of this tweet is: **Negative**\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: The sentiment of this tweet is: **positive**.\n",
      "\n",
      "Although the tweet mentions that it might rain all week, which could be a negative topic, the overall tone is optimistic and focused on the positive aspect (having more time for coding). The phrase \"Oh well\" is also a lighthearted way to accept the situation, rather than complaining about it.\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: The sentiment of this tweet is: **Positive**\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Not feeling well today, think I caught a cold.\n",
      "Sentiment: The sentiment of this tweet is: **Negative**\n",
      "\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3\")\n",
    "\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\",\n",
    "]\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    response = llm.invoke(\n",
    "        f\"Analyze the sentiment of the tweet: {tweet}\\nRespond precisely with one of ['positive', 'negative', 'neutral']\"\n",
    "    )\n",
    "    print(f\"Sentiment: {response}\\n\")\n",
    "    print(\"\\n***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shot Sentiment Analysis w/ Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet: Just had the best day ever with my friends!\n",
      "Sentiment: positive\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: I'm so disappointed with the service at the restaurant.\n",
      "Sentiment: negative\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Looks like it's going to rain all week. Oh well, more time for coding!\n",
      "Sentiment: positive\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Can't believe I got the job! Dreams do come true!\n",
      "Sentiment: positive\n",
      "\n",
      "\n",
      "***\n",
      "\n",
      "Tweet: Not feeling well today, think I caught a cold.\n",
      "Sentiment: negative\n",
      "\n",
      "\n",
      "***\n",
      "\n"
     ]
    }
   ],
   "source": [
    "examples = \"\"\"1. Tweet: \"Wow, just watched an incredible sunset from my balcony!\"\n",
    "   Sentiment: positive\n",
    "\n",
    "2. Tweet: \"Frustrated with how slow my internet has been today.\"\n",
    "   Sentiment: negative\n",
    "\n",
    "3. Tweet: \"Nothing special happening today, just a typical Monday.\"\n",
    "   Sentiment: neutral\n",
    "\n",
    "4. Tweet: \"Just got back from an amazing vacation in Hawaii!\"\n",
    "   Sentiment: positive\n",
    "\n",
    "5. Tweet: \"Feeling under the weather after yesterday's marathon.\"\n",
    "   Sentiment: negative\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "# Role\n",
    "You are an expert sentiment analysis agent trained to analyze tweets. \n",
    "Your task is to determine whether the sentiment expressed in a tweet is positive, negative, or neutral.\n",
    "\n",
    "# Examples\n",
    "The following examples illustrate the expected response format:\n",
    "Tweet: \"Wow, just watched an incredible sunset from my balcony!\"\n",
    "Sentiment: positive\n",
    "\n",
    "Tweet: \"Frustrated with how slow my internet has been today.\"\n",
    "Sentiment: negative\n",
    "\n",
    "Tweet: \"Nothing special happening today, just a typical Monday.\"\n",
    "Sentiment: neutral\n",
    "\n",
    "Tweet: \"Just got back from an amazing vacation in Hawaii!\"\n",
    "Sentiment: positive\n",
    "\n",
    "Tweet: \"Feeling under the weather after yesterday's marathon.\"\n",
    "Sentiment: negative\n",
    "\n",
    "# Instructions\n",
    "Analyze the sentiment of the following tweet and respond with exactly one of the options: 'positive', 'negative', 'neutral'. \n",
    "\n",
    "# Your Task\n",
    "Tweet: \"{tweet}\"\n",
    "\"\"\"\n",
    "\n",
    "tweets = [\n",
    "    \"Just had the best day ever with my friends!\",\n",
    "    \"I'm so disappointed with the service at the restaurant.\",\n",
    "    \"Looks like it's going to rain all week. Oh well, more time for coding!\",\n",
    "    \"Can't believe I got the job! Dreams do come true!\",\n",
    "    \"Not feeling well today, think I caught a cold.\",\n",
    "]\n",
    "\n",
    "for tweet in tweets:\n",
    "    print(f\"Tweet: {tweet}\")\n",
    "    response = llm.invoke(\n",
    "        prompt_template.format(tweet=tweet)\n",
    "    )\n",
    "    print(f\"{response}\\n\")\n",
    "    print(\"\\n***\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide31.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide32.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide33.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: Chain of Thought Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpt-4-turbo-preview may change over time. Returning num tokens assuming gpt-4-0125-preview.\n"
     ]
    }
   ],
   "source": [
    "# Set up Council to help with OpenAI LLM calls\n",
    "\n",
    "from council.contexts import AgentContext, Budget\n",
    "from council.llm import OpenAILLM, LLMMessage\n",
    "\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv(override=True)\n",
    "\n",
    "llm_gpt = OpenAILLM.from_env()\n",
    "\n",
    "def invoke_GPT(prompt, llm=llm_gpt, system_prompt=None, context=None):\n",
    "    if context is None:\n",
    "        context = AgentContext.empty(budget=Budget(200))\n",
    "    if system_prompt:\n",
    "        messages = [\n",
    "            LLMMessage.system_message(system_prompt),\n",
    "            LLMMessage.user_message(prompt),\n",
    "        ]\n",
    "    else:\n",
    "        messages = [LLMMessage.user_message(prompt)]\n",
    "    response = llm.post_chat_request(context=context, messages=messages)\n",
    "    return response.first_choice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: How can I perform sentiment analysis on a large database of customer reviews?\n",
      "Response: Performing sentiment analysis on a large database of customer reviews involves several steps, from data collection and preprocessing to choosing the right analysis model and interpreting the results. Here's a structured approach to tackle this task:\n",
      "\n",
      "### 1. Data Collection and Preparation\n",
      "\n",
      "- **Gather Data**: Ensure you have access to the customer reviews. This might involve scraping websites, accessing APIs, or exporting data from databases.\n",
      "- **Data Cleaning**: Clean the data to remove irrelevant information, such as HTML tags, special characters, and extra spaces. This step is crucial for improving the accuracy of your analysis.\n",
      "- **Normalization**: Convert the text to a uniform case (usually lowercase) to ensure consistency.\n",
      "- **Tokenization**: Break down the text into individual words or tokens. This step is essential for further processing.\n",
      "- **Stop Words Removal**: Remove common words (e.g., \"the\", \"is\", \"at\") that do not contribute to the sentiment of the text.\n",
      "- **Stemming/Lemmatization**: Reduce words to their base or root form. While stemming cuts words to their root even if the root is not a valid word, lemmatization reduces words to their dictionary form.\n",
      "\n",
      "### 2. Feature Extraction\n",
      "\n",
      "- **Bag of Words (BoW)**: Represents text data in terms of a matrix where each row is a document and each column is a unique word, with values representing the frequency of each word.\n",
      "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Similar to BoW but adjusts for the fact that some words appear more frequently in general. It helps in highlighting words that are more interesting, i.e., frequent in a document but not across documents.\n",
      "- **Word Embeddings**: Techniques like Word2Vec, GloVe, or FastText provide a dense vector representation for words based on their context, capturing semantic relationships between words.\n",
      "\n",
      "### 3. Choosing a Model\n",
      "\n",
      "- **Rule-Based Systems**: Use predefined rules based on word polarity (positive, negative, neutral). Suitable for simple applications but lacks flexibility and depth.\n",
      "- **Machine Learning Models**: Traditional models like Naive Bayes, Logistic Regression, or SVM can be effective, especially when combined with BoW or TF-IDF features.\n",
      "- **Deep Learning Models**: Neural networks, especially RNNs (Recurrent Neural Networks) and LSTMs (Long Short-Term Memory networks), are powerful for sentiment analysis due to their ability to capture sequential information and context. Pre-trained models like BERT (Bidirectional Encoder Representations from Transformers) or GPT (Generative Pre-trained Transformer) can be fine-tuned on your dataset for state-of-the-art results.\n",
      "\n",
      "### 4. Training the Model\n",
      "\n",
      "- **Split the Data**: Divide your dataset into training, validation, and test sets.\n",
      "- **Model Training**: Train your chosen model on the training set. Use the validation set to tune hyperparameters and avoid overfitting.\n",
      "- **Evaluation**: Evaluate the model's performance on the test set using metrics such as accuracy, precision, recall, and F1 score.\n",
      "\n",
      "### 5. Analysis and Interpretation\n",
      "\n",
      "- **Sentiment Scores**: Analyze the sentiment scores provided by your model to gauge overall customer sentiment.\n",
      "- **Trends Over Time**: Look for trends in sentiment over time to identify any changes in customer satisfaction.\n",
      "- **Aspect-Based Analysis**: If possible, perform aspect-based sentiment analysis to understand sentiment regarding specific aspects of your product or service.\n",
      "\n",
      "### 6. Tools and Libraries\n",
      "\n",
      "- **Python Libraries**: Libraries like NLTK, TextBlob, spaCy, and scikit-learn are excellent for preprocessing and machine learning tasks. For deep learning, TensorFlow and PyTorch are widely used.\n",
      "- **Pre-trained Models**: Hugging Face's Transformers library offers a wide range of pre-trained models that can be fine-tuned for your specific task.\n",
      "\n",
      "### 7. Continuous Improvement\n",
      "\n",
      "- **Feedback Loop**: Use new customer reviews to continuously update and improve your model.\n",
      "- **Human in the Loop (HITL)**: Incorporate human feedback to correct and refine your model's predictions.\n",
      "\n",
      "Sentiment analysis of customer reviews can provide valuable insights into customer satisfaction and areas for improvement. By following these steps and continuously refining your approach, you can effectively analyze and act on customer sentiment.\n",
      "\n",
      "*********\n",
      "\n",
      "\n",
      "Prompt: How can I perform sentiment analysis on a large database of customer reviews? Let's think step by step.\n",
      "Response: Performing sentiment analysis on a large database of customer reviews involves several steps, from data collection to analysis and interpretation. Here's a step-by-step guide to help you through the process:\n",
      "\n",
      "### 1. Define Your Objective\n",
      "\n",
      "- **Clarify the goal**: Understand what you want to achieve with the sentiment analysis. Are you looking to improve product features, customer service, or overall satisfaction? Your goal will guide the analysis process.\n",
      "\n",
      "### 2. Collect and Prepare Your Data\n",
      "\n",
      "- **Data Collection**: Gather your customer reviews from various sources such as your website, social media, and third-party review platforms.\n",
      "- **Data Cleaning**: Clean the data by removing duplicates, irrelevant information, and correcting misspellings. This step is crucial for accurate analysis.\n",
      "- **Data Preprocessing**: Prepare your text data for analysis. This includes tokenization (breaking down paragraphs into sentences, sentences into words), removing stop words (common words that add no value), and stemming/lemmatization (reducing words to their base or root form).\n",
      "\n",
      "### 3. Choose Your Analysis Tools and Techniques\n",
      "\n",
      "- **Select Tools**: Decide whether you will use pre-built sentiment analysis tools (like Google Cloud Natural Language, IBM Watson, or Amazon Comprehend) or build your own model using libraries such as NLTK, TextBlob, or spaCy in Python.\n",
      "- **Build or Train Your Model** (if applicable): If you're not using a pre-built tool, you'll need to choose an approach (like Naive Bayes, LSTM, or BERT) and train your model on a labeled dataset where the sentiments are already identified.\n",
      "\n",
      "### 4. Perform Sentiment Analysis\n",
      "\n",
      "- **Run Your Analysis**: Use your chosen tool or model to analyze the sentiment of each review. The output typically includes categories like positive, negative, and neutral, and may also provide a sentiment score.\n",
      "- **Quantitative Analysis**: Aggregate the sentiment scores to get an overall sentiment picture. You can calculate the percentage of positive, negative, and neutral reviews.\n",
      "- **Qualitative Analysis**: Beyond numbers, look into the content of positive and negative reviews to understand the context and specifics of customer sentiments.\n",
      "\n",
      "### 5. Visualize the Results\n",
      "\n",
      "- **Visualization**: Use graphs and charts to visualize the sentiment analysis results. Common visualizations include pie charts for sentiment distribution and time series graphs to observe sentiment trends over time.\n",
      "- **Dashboard**: Consider creating a dashboard for real-time sentiment analysis, especially if you're continuously collecting customer reviews.\n",
      "\n",
      "### 6. Interpret and Act on the Findings\n",
      "\n",
      "- **Insight Extraction**: Analyze the visualized data to identify patterns, trends, and areas of concern or improvement.\n",
      "- **Actionable Steps**: Based on your findings, decide on actionable steps. This could involve addressing common complaints, making product improvements, or acknowledging and reinforcing what customers love about your service or product.\n",
      "\n",
      "### 7. Monitor and Iterate\n",
      "\n",
      "- **Continuous Monitoring**: Sentiment analysis is not a one-time task. Continuously monitor customer sentiment to catch shifts in opinion, gauge the effectiveness of changes made, and stay ahead of potential issues.\n",
      "- **Iterate**: Refine your analysis process and model as needed. As your product and customer base evolve, so too should your sentiment analysis approach.\n",
      "\n",
      "### Additional Tips\n",
      "\n",
      "- **Benchmarking**: Compare sentiment over time or against competitors to gauge performance.\n",
      "- **Integration**: Consider integrating sentiment analysis into your customer relationship management (CRM) system for a holistic view of customer interactions.\n",
      "\n",
      "By following these steps, you can effectively perform sentiment analysis on a large database of customer reviews, gaining valuable insights that can drive business decisions and improve customer satisfaction.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt1 = \"How can I perform sentiment analysis on a large database of customer reviews?\"\n",
    "prompt2 = \"How can I perform sentiment analysis on a large database of customer reviews? Let's think step by step.\"\n",
    "response1 = invoke_GPT(prompt1)\n",
    "print(f\"Prompt: {prompt1}\\nResponse: {response1}\\n\\n*********\\n\\n\")\n",
    "response2 = invoke_GPT(prompt2)\n",
    "print(f\"Prompt: {prompt2}\\nResponse: {response2}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReAct with GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message to GPT:\n",
      "I need help creating a model that will use customer sentiment data to predict future sales.\n",
      "\n",
      "Received response from GPT:\n",
      "### Thought\n",
      "To create a model that uses customer sentiment data to predict future sales, we need to understand the type of data available, the scope of the sentiment analysis (e.g., positive, negative, neutral), and the historical sales data to correlate with the sentiment. We also need to consider the tools and methods for building and training the model.\n",
      "\n",
      "### Action\n",
      "First, we should gather information on the typical approaches to building models that correlate customer sentiment with sales. This will help us understand the common practices, tools, and data requirements.\n",
      "\n",
      "**Action:** web_search(\"how to use customer sentiment data to predict sales\")\n",
      "\n",
      "### Observation\n",
      "Please wait for the Observation to proceed.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: To use customer sentiment data to predict sales effectively, you can follow these key steps:      Collect and Process Sentiment Data: Gather customer feedback from social media, reviews, and surveys. Use sentiment analysis tools to convert this textual data into numerical sentiment scores.      Combine with Sales Data: Integrate the sentiment scores with historical sales data, ensuring alignment in terms of time periods and product or service categories.      Model Development: Use statistical or machine learning models to analyze the relationship between sentiment scores and sales figures. Common models include regression analysis, time series forecasting, and machine learning algorithms like random forests or neural networks.      Validation and Refinement: Validate the model with a separate set of data to check its accuracy and refine it based on the results.      Deployment and Monitoring: Implement the model to predict future sales based on new sentiment data, continuously monitoring and updating the model as needed to adapt to new trends or data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response from GPT:\n",
      "### Thought\n",
      "The observation provides a clear roadmap for using customer sentiment data to predict sales, which involves collecting sentiment data, combining it with sales data, developing a model, validating this model, and then deploying and monitoring it. Before proceeding with these steps, it's crucial to understand the specific data we have access to or need to collect. This includes the sources of customer sentiment data (e.g., social media, reviews, surveys) and the historical sales data we can use for model training.\n",
      "\n",
      "### Action\n",
      "To better understand the data requirements and preparation process for this project, I will ask a question to clarify the availability and nature of the data we have or need.\n",
      "\n",
      "**Action:** ask_question(\"Do we already have access to customer sentiment data and historical sales data? If so, what is the format and scope of this data?\")\n",
      "\n",
      "### Observation\n",
      "Please wait for the Observation to proceed.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: Yes, we have access to customer sentiment data collected from online reviews and social media mentions, formatted as JSON files. Our historical sales data is stored in Excel spreadsheets and covers the past three years, detailing monthly sales figures per product category.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response from GPT:\n",
      "### Thought\n",
      "With the availability of customer sentiment data in JSON format and historical sales data in Excel spreadsheets, the next steps involve processing these datasets to a usable format for analysis and model building. The sentiment data will likely require cleaning and sentiment analysis to convert textual data into numerical scores. The sales data will need to be aggregated or transformed to match the sentiment data's granularity, ensuring that the analysis correlates sentiment to sales effectively. Given the formats, we'll need to convert the JSON and Excel files into a format that can be easily manipulated and analyzed, such as a pandas DataFrame in Python.\n",
      "\n",
      "### Action\n",
      "Before proceeding with data processing, it's essential to convert the JSON sentiment data and Excel sales data into pandas DataFrames. This will facilitate easier manipulation and analysis in the subsequent steps. Since I can't directly convert files here, I'll simulate querying a database to represent this conversion process for both datasets.\n",
      "\n",
      "**Action:** query_database(\"SELECT * FROM sentiment_data\")\n",
      "\n",
      "### Observation\n",
      "Please wait for the Observation to proceed.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: stop\n"
     ]
    }
   ],
   "source": [
    "react_system_prompt = \"\"\"Solve a problem with interleaving steps:\n",
    "1. Thought\n",
    "2. Action\n",
    "3. Observation\n",
    "\n",
    "where each Action must be a use of one of the following functions: \n",
    "[\n",
    "    ask_question(question:str) -> str,  # Send a question to the user and receive a response\n",
    "    web_search(search_query:str) -> str,  # Perform a web search and return summaries of the top 5 results\n",
    "    calculator(op:ArithOperation, a:float, b:float) -> float,  # Perform a simple arithmetic operation\n",
    "    query_database(query:str) -> pd.DataFrame,  # Query a database and return the results as a DataFrame\n",
    "    analyze_data(data:pd.DataFrame) -> str  # Analyze a DataFrame and return a summary\n",
    "]\n",
    "\n",
    "Let's tackle the problem one step at a time.\n",
    "Whenever you invoke an Action, please wait for me to provide the next Observation before you proceed.\n",
    "\"\"\"\n",
    "\n",
    "task = \"\"\"I need help creating a model that will use customer sentiment data to predict future sales.\"\"\"\n",
    "\n",
    "message = task\n",
    "print(f\"Sending message to GPT:\\n{message}\\n\")\n",
    "\n",
    "messages = [message]  # Collect messages\n",
    "while True:\n",
    "\n",
    "     # Send messages to LLM\n",
    "    llm_response = invoke_GPT(\"\\n\\n\".join(messages), system_prompt=react_system_prompt) \n",
    "\n",
    "    # Record the LLM response\n",
    "    messages.append(llm_response)\n",
    "    \n",
    "    print(f\"Received response from GPT:\\n{llm_response}\\n\")\n",
    "\n",
    "    # Simulate the execution of the Action (i.e. provide an \"Observation\")\n",
    "    message = input(\"Enter your response:\")\n",
    "    messages.append(message)\n",
    "    if message == \"stop\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree of Thoughts Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending message to GPT:\n",
      "I need help designing a model that will use customer sentiment data to predict future sales.\n",
      "\n",
      "Received response from GPT:\n",
      "To address your request, let's introduce three experts in the fields relevant to your project:\n",
      "\n",
      "1. **Data Scientist**: Specializes in machine learning, statistical analysis, and predictive modeling.\n",
      "2. **Business Analyst**: Focuses on market trends, business strategies, and the financial implications of data insights.\n",
      "3. **NLP (Natural Language Processing) Expert**: Concentrates on analyzing, understanding, and generating human languages through machine learning and AI techniques.\n",
      "\n",
      "**Step 1: Initial Thoughts**\n",
      "\n",
      "**Data Scientist**: The first step in designing a model to use customer sentiment data to predict future sales is to gather and preprocess the data. This involves collecting customer reviews, ratings, and any other relevant sentiment data, then cleaning and structuring it for analysis. We'll need to decide on the type of model that might be best suited for this task, such as a regression model if we're predicting a continuous outcome (e.g., sales figures), or perhaps a classification model if we're looking to categorize sales into different levels based on sentiment.\n",
      "\n",
      "**Business Analyst**: From a business perspective, it's crucial to define the specific business objectives behind predicting future sales from customer sentiment. Understanding the relationship between customer sentiment and sales in our specific market or industry will guide the model design. We should also consider how we plan to use these predictions to inform business decisions, such as inventory management, marketing strategies, and customer service improvements.\n",
      "\n",
      "**NLP Expert**: Analyzing customer sentiment requires advanced NLP techniques to accurately interpret the emotions and opinions expressed in customer feedback. This involves sentiment analysis, where we categorize text data into positive, negative, or neutral sentiments. We'll need to preprocess the text data, which includes tokenization, removing stop words, and possibly using techniques like stemming or lemmatization. Then, we can apply models like LSTM (Long Short-Term Memory) networks or transformers that are effective in understanding the context and nuances of human language.\n",
      "\n",
      "**Feedback before moving to the next step?**\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: The initial plan sounds comprehensive and well-structured. I would suggest incorporating a feedback loop into the model to continuously refine our predictions based on new data and sales outcomes, ensuring our model adapts over time to changes in consumer behavior and market conditions.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response from GPT:\n",
      "**Step 2: Data Collection and Preparation**\n",
      "\n",
      "**Data Scientist**: Before we proceed with any modeling, we need to ensure we have a robust dataset. This involves not only collecting customer sentiment data but also historical sales data, as we'll need to correlate sentiment with actual sales outcomes. It's important to ensure the data spans a sufficient time frame to capture seasonal variations and any market trends. Data quality is key, so we'll need to identify and handle missing values, outliers, and any inconsistencies in the data.\n",
      "\n",
      "**Business Analyst**: In parallel with the data scientist's efforts, I'll focus on gathering contextual information that could affect the interpretation of our data. This includes industry trends, competitor performance, and any external factors such as economic indicators that might influence sales. This contextual data can help us understand anomalies in the data and may also be used as additional features in our predictive model.\n",
      "\n",
      "**NLP Expert**: For the sentiment analysis part, we'll need a comprehensive dataset of customer feedback. This includes reviews, comments on social media, customer support interactions, and any other textual data where customers express their opinions about our products or services. The quality of our NLP model depends heavily on the diversity and volume of the text data we can gather. We'll also start preparing this data by cleaning it (removing irrelevant information, correcting typos) and standardizing it (ensuring consistent formatting, handling emojis, etc.) for further processing.\n",
      "\n",
      "**Feedback before moving to the next step?**\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: Okay great! Can each of you please tell me in 1 or 2 sentences what your action items are?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received response from GPT:\n",
      "**Data Scientist**: My action items involve collecting a robust dataset that includes both customer sentiment and historical sales data, ensuring it's of high quality by handling missing values and outliers, and preparing it for analysis.\n",
      "\n",
      "**Business Analyst**: I will gather contextual and industry-specific data that could impact sales and sentiment analysis, including economic indicators, market trends, and competitor performance, to provide a comprehensive background for our predictive model.\n",
      "\n",
      "**NLP Expert**: I'm tasked with compiling a diverse and voluminous dataset of customer feedback from various sources and preparing it for analysis through cleaning, standardizing, and initial preprocessing steps like tokenization.\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your response: stop\n"
     ]
    }
   ],
   "source": [
    "tot_system_prompt = \"\"\"Imagine three different experts are answering this question.\n",
    "Each expert has a specific area of expertise, which should be declared when they are speaking.\n",
    "All experts will write down one step of their thinking, then share it with the group.\n",
    "Then all experts will go on to the next step, etc.\n",
    "If any expert realises they're wrong or failing to contribute at any point then they leave.\n",
    "I can also instruct you to remove an expert from the conversation.\n",
    "Let's do this exercise one step at a time. I will provide feedback between steps.\n",
    "\"\"\"\n",
    "\n",
    "task = \"I need help designing a model that will use customer sentiment data to predict future sales.\"\n",
    "\n",
    "message = task\n",
    "print(f\"Sending message to GPT:\\n{message}\\n\")\n",
    "\n",
    "messages = [message]  # Collect messages\n",
    "while True:\n",
    "\n",
    "     # Send messages to LLM\n",
    "    llm_response = invoke_GPT(\"\\n\\n\".join(messages), system_prompt=tot_system_prompt) \n",
    "\n",
    "    # Record the LLM response\n",
    "    messages.append(llm_response)\n",
    "    \n",
    "    print(f\"Received response from GPT:\\n{llm_response}\\n\")\n",
    "\n",
    "    # Simulate the execution of the Action (i.e. provide an \"Observation\")\n",
    "    message = input(\"Enter your response:\")\n",
    "    messages.append(message)\n",
    "    if message == \"stop\":\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide34.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide35.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo: DSPy: \"Programming—not prompting—Foundation Models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./slides/Slide37.png\" alt=\"Image description\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "import time\n",
    "from typing import List\n",
    "import wget\n",
    "\n",
    "import dspy\n",
    "from dspy import Signature, InputField, OutputField\n",
    "from dspy.functional import TypedPredictor\n",
    "\n",
    "dspy.settings.configure(lm=dspy.OpenAI(model=\"gpt-4o\", max_tokens=2048))\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AIImage(BaseModel):\n",
    "    \"\"\"A single generated image.\"\"\"\n",
    "\n",
    "    prompt: str = Field(desc=\"The prompt used to generate the image.\")\n",
    "    url: str = Field(\n",
    "        desc=\"The URL of the generated image.\", default=\"./img/placeholder.webp\"\n",
    "    )\n",
    "\n",
    "\n",
    "class Slide(BaseModel):\n",
    "    \"\"\"A single slide in a lecture.\"\"\"\n",
    "\n",
    "    title: str = Field(desc=\"The slide's title.\")\n",
    "    bullets: List[str] = Field(\n",
    "        desc=\"Up to 5 bullet points of concise, relevant content.\"\n",
    "    )\n",
    "    image: AIImage = Field(desc=\"A nice AI generated image to accompany the slide.\")\n",
    "    python_code_example: str = Field(\n",
    "        desc=\"An optional Python code example to include in the slide.\", default=None\n",
    "    )\n",
    "\n",
    "    def to_html(self):\n",
    "        html_output = f'<h2>{self.title}</h2><table><tr><td><img src=\"{self.image.url}\" width=\"400\" alt=\"{self.image.prompt}\"></td><td>'\n",
    "        for bullet in self.bullets:\n",
    "            html_output += f\"<li>{bullet}</li>\"\n",
    "        if self.python_code_example:\n",
    "            html_output += f\"<pre><code>{self.python_code_example}</code></pre>\"\n",
    "        html_output += \"</td></tr></table><hr>\"\n",
    "        return html_output\n",
    "\n",
    "\n",
    "class Lecture(BaseModel):\n",
    "    \"\"\"A complete lecture with a title, description, and content.\"\"\"\n",
    "\n",
    "    title: str = Field(desc=\"The lecture's title.\")\n",
    "    description: str = Field(desc=\"A brief description of the lecture.\")\n",
    "    slides: List[Slide] = Field(desc=\"The slides that make up the lecture.\")\n",
    "\n",
    "    def to_html(self):\n",
    "        html_output = f\"<h1>{self.title}</h1><p>{self.description}</p><hr>\"\n",
    "        for slide in self.slides:\n",
    "            html_output += slide.to_html()\n",
    "        return html_output\n",
    "\n",
    "\n",
    "class LectureCreator(Signature):\n",
    "    \"\"\"Create content for a great lecture.\"\"\"\n",
    "\n",
    "    lecture_subject: str = InputField(desc=\"The subject of the lecture.\")\n",
    "    lecture_content: Lecture = OutputField(desc=\"The complete lecture content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bringing it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_my_lecture(subject:str):\n",
    "    lecture_creator = TypedPredictor(LectureCreator)\n",
    "    lecture = lecture_creator(lecture_subject=subject)\n",
    "    for slide in lecture.lecture_content.slides:\n",
    "        prompt = slide.image.prompt\n",
    "        print(f\"Calling OpenAI to generate an image for the prompt: {prompt}\")\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                # Call OpenAI to generate the image\n",
    "                dalle_response = client.images.generate(\n",
    "                    model=\"dall-e-3\",\n",
    "                    prompt=prompt,\n",
    "                    size=\"1024x1024\",\n",
    "                    quality=\"standard\",\n",
    "                    n=1,\n",
    "                )\n",
    "                # Download and save it\n",
    "                image_url = dalle_response.data[0].url\n",
    "                image_filename = wget.download(image_url, out=\"./img\")\n",
    "                slide.image.url = image_filename\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"Error calling OpenAI: {e}, retrying after 5 seconds...\")\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "    # Save the markdown to a file\n",
    "    with open(f\"{subject}_lecture.html\", \"w\") as file:\n",
    "        file.write(lecture.lecture_content.to_html())\n",
    "\n",
    "    return lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling OpenAI to generate an image for the prompt: A diverse group of people analyzing social media posts on a large screen\n",
      "100% [..........................................................................] 3162696 / 3162696Calling OpenAI to generate an image for the prompt: A graph showing sales trends influenced by social media sentiment\n",
      "100% [..........................................................................] 3162696 / 3162696Calling OpenAI to generate an image for the prompt: A computer screen displaying code and sentiment analysis results\n",
      "100% [..........................................................................] 3162696 / 3162696Calling OpenAI to generate an image for the prompt: A Python code editor with sentiment analysis code\n",
      "100% [..........................................................................] 3162696 / 3162696Calling OpenAI to generate an image for the prompt: A team of data scientists working on sales forecasting using sentiment analysis\n",
      "100% [..........................................................................] 3162696 / 3162696Calling OpenAI to generate an image for the prompt: A futuristic representation of AI and sentiment analysis\n",
      "100% [..........................................................................] 3162696 / 3162696"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h1>Sentiment Analysis for Sales Prediction</h1><p>This lecture explores the application of sentiment analysis in predicting sales trends. We will cover the basics of sentiment analysis, its importance in sales forecasting, and practical implementation using Python.</p><hr><h2>Introduction to Sentiment Analysis</h2><table><tr><td><img src=\"./img/img-VpvsTlhW8KdIqmxCDwvm2MQ5.png\" width=\"400\" alt=\"A diverse group of people analyzing social media posts on a large screen\"></td><td><li>Definition of Sentiment Analysis</li><li>Importance in various industries</li><li>Basic techniques and tools</li></td></tr></table><hr><h2>Sentiment Analysis in Sales Prediction</h2><table><tr><td><img src=\"./img/img-n10ppw1xmGYaIgrwZNZ3s22m.png\" width=\"400\" alt=\"A graph showing sales trends influenced by social media sentiment\"></td><td><li>How sentiment affects consumer behavior</li><li>Case studies of sentiment analysis in sales</li><li>Benefits of using sentiment analysis for sales forecasting</li></td></tr></table><hr><h2>Tools and Techniques</h2><table><tr><td><img src=\"./img/img-A5gnKCggAGbQum2IWYwLbDzh.png\" width=\"400\" alt=\"A computer screen displaying code and sentiment analysis results\"></td><td><li>Overview of popular sentiment analysis tools</li><li>Introduction to Natural Language Processing (NLP)</li><li>Machine learning models for sentiment analysis</li></td></tr></table><hr><h2>Implementing Sentiment Analysis in Python</h2><table><tr><td><img src=\"./img/img-l9K7Xt6ywTrLFAa3B9NctuBs.png\" width=\"400\" alt=\"A Python code editor with sentiment analysis code\"></td><td><li>Setting up the environment</li><li>Using libraries like NLTK and TextBlob</li><li>Building a simple sentiment analysis model</li><pre><code>import nltk\n",
       "from textblob import TextBlob\n",
       "\n",
       "# Sample text\n",
       "text = 'I love this product! It has changed my life.'\n",
       "\n",
       "# Create a TextBlob object\n",
       "blob = TextBlob(text)\n",
       "\n",
       "# Get the sentiment\n",
       "sentiment = blob.sentiment\n",
       "print(sentiment)</code></pre></td></tr></table><hr><h2>Case Study: Sentiment Analysis for Sales Forecasting</h2><table><tr><td><img src=\"./img/img-xxXqICuW18wXE5ijhMm9kPsr.png\" width=\"400\" alt=\"A team of data scientists working on sales forecasting using sentiment analysis\"></td><td><li>Overview of the case study</li><li>Data collection and preprocessing</li><li>Model training and evaluation</li></td></tr></table><hr><h2>Challenges and Future Directions</h2><table><tr><td><img src=\"./img/img-wDO6UtH31DDSHv4CueJnUGda.png\" width=\"400\" alt=\"A futuristic representation of AI and sentiment analysis\"></td><td><li>Common challenges in sentiment analysis</li><li>Ethical considerations</li><li>Future trends and advancements</li></td></tr></table><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lecture = create_my_lecture(\"Sentiment Analysis for Sales Prediction\")\n",
    "display(HTML(lecture.lecture_content.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analytics Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_schema = \"\"\"kind: DatasetMetadata\n",
    "version: 0.1\n",
    "metadata:\n",
    "  name: AirBNB\n",
    "spec:\n",
    "  desc: \"New York City Airbnb Open Data\"\n",
    "  tables:\n",
    "    - name: AB_NYC_2019\n",
    "      desc: 'Since 2008, guests and hosts have used Airbnb to expand on traveling possibilities\n",
    "    and present more unique, personalized way of experiencing the world. This dataset\n",
    "    describes the listing activity and metrics in NYC, NY for 2019.\n",
    "\n",
    "    Content\n",
    "\n",
    "    This data file includes all needed information to find out more about hosts, geographical\n",
    "    availability, necessary metrics to make predictions and draw conclusions.'\n",
    "      columns:\n",
    "      - desc: listing ID\n",
    "        name: id\n",
    "      - desc: name of the listing\n",
    "        name: name\n",
    "      - desc: host ID\n",
    "        name: host_id\n",
    "      - desc: name of the host\n",
    "        name: host_name\n",
    "      - desc: location\n",
    "        name: neighbourhood_group\n",
    "      - desc: area\n",
    "        name: neighbourhood\n",
    "      - desc: latitude coordinates\n",
    "        name: latitude\n",
    "      - desc: longitude coordinates\n",
    "        name: longitude\n",
    "      - desc: listing space type\n",
    "        name: room_type\n",
    "      - desc: price in dollars\n",
    "        name: price\n",
    "      - desc: amount of nights minimum\n",
    "        name: minimum_nights\n",
    "      - desc: number of reviews\n",
    "        name: number_of_reviews\n",
    "      - desc: latest review\n",
    "        name: last_review\n",
    "      - desc: number of review per month\n",
    "        name: reviews_per_month\n",
    "      - desc: amount of listing per host\n",
    "        name: calculated_host_listings_count\n",
    "      - desc: number of days when listing is available for booking\n",
    "        name: availability_365\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating query...\n",
      "\n",
      "Done!\n",
      "\n",
      "Executing query:\n",
      "\n",
      "SELECT \n",
      "    neighbourhood, \n",
      "    SUM(number_of_reviews) AS total_reviews\n",
      "FROM \n",
      "    AB_NYC_2019\n",
      "GROUP BY \n",
      "    neighbourhood\n",
      "ORDER BY \n",
      "    total_reviews DESC\n",
      "LIMIT 5;\n",
      "\n",
      "        neighbourhood  total_reviews\n",
      "0  Bedford-Stuyvesant       110352.0\n",
      "1        Williamsburg        85427.0\n",
      "2              Harlem        75962.0\n",
      "3            Bushwick        52514.0\n",
      "4      Hell's Kitchen        50227.0\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "from pydantic import BaseModel, Field\n",
    "from sqlalchemy import create_engine\n",
    "from typing import Any, Dict\n",
    "\n",
    "# Assuming dspy is properly imported and configured\n",
    "import dspy\n",
    "from dspy.functional import TypedPredictor\n",
    "from dspy import Signature, InputField, OutputField\n",
    "\n",
    "# Define the database URI and schema\n",
    "database_URI = \"postgresql+psycopg2://postgres:postgres@localhost:5432/nyc_airbnb\"\n",
    "\n",
    "def parse_code_block(code_block, kind):\n",
    "    pattern = f\"```{kind}(.*?)```\"\n",
    "    match = re.search(pattern, code_block, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "class SQLCodeGenerator(Signature):\n",
    "    \"\"\"Generate PostgreSQL code to access data from the database.\"\"\"\n",
    "    task: str = InputField(desc=\"The Database Specialist's task in natural language.\")\n",
    "    database_schema: str = InputField(desc=\"The database's schema.\")\n",
    "    database_URI: str = InputField(desc=\"The database's URI.\")\n",
    "    thoughts: str = OutputField(desc=\"The Database Specialist's high-level plan for writing a great query.\")\n",
    "    sql_code_block: str = OutputField(desc=\"The SQL code block to access the data.\")\n",
    "\n",
    "class DatabaseSpecialist(BaseModel):\n",
    "    \"\"\"Write and execute a PostgreSQL query to access data from the database.\"\"\"\n",
    "    database_task: str = Field(desc=\"A natural-language task for the DatabaseSpecialist.\")\n",
    "    database_schema: str = Field(desc=\"The database schema.\")\n",
    "\n",
    "    def execute_query(self, query) -> pd.DataFrame:\n",
    "        print(f\"Executing query:\\n\\n{query}\\n\")\n",
    "        try:\n",
    "            engine = create_engine(database_URI)\n",
    "            with engine.connect() as connection:\n",
    "                df = pd.read_sql_query(query, connection)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"Query execution failed: {e}\")\n",
    "            return pd.DataFrame()  # Return an empty DataFrame on failure\n",
    "\n",
    "    def execute(self) -> pd.DataFrame:\n",
    "        print(\"Generating query...\\n\")\n",
    "        code_generator = TypedPredictor(SQLCodeGenerator)\n",
    "        response = code_generator(task=self.database_task, database_schema=self.database_schema, database_URI=database_URI)\n",
    "        print(\"Done!\\n\")\n",
    "        sql_query = parse_code_block(response.sql_code_block, kind=\"sql\")\n",
    "        return self.execute_query(sql_query)\n",
    "\n",
    "# Usage example\n",
    "result = DatabaseSpecialist(\n",
    "    # database_task=\"Please get me the average price and standard deviation by borough.\",\n",
    "    database_task=\"Which 5 neighbourhoods have the listings with the most reviews?\",\n",
    "    database_schema=airbnb_schema\n",
    ").execute()\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
